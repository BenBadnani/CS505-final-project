{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "96da3e8a",
      "metadata": {
        "id": "96da3e8a"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from google.colab import files\n",
        "import bcolz\n",
        "import pickle\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import csv\n",
        "import json\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import spacy\n",
        "import re\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "#stopwords = nlp.Defaults.stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ghIfS47AVBd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghIfS47AVBd1",
        "outputId": "17c47fec-b7d7-45ee-b724-ca03072e65fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bcolz\n",
            "  Downloading bcolz-1.2.1.tar.gz (1.5 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 92 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 133 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 184 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 194 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 204 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 215 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 225 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 235 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 245 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 256 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 266 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 276 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 286 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 296 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 307 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 317 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 327 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 337 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 348 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 358 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 368 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 378 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 389 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 399 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 409 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 419 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 430 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 440 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 450 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 460 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 471 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 481 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 491 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 501 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 512 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 522 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 532 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 542 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 552 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 563 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 573 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 583 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 593 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 604 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 614 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 624 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 634 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 645 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 655 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 665 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 675 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 686 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 696 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 706 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 716 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 727 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 737 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 747 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 757 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 768 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 778 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 788 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 798 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 808 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 819 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 829 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 839 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 849 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 860 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 870 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 880 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 890 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 901 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 911 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 921 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 931 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 942 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 952 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 962 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 972 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 983 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 993 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.0 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.0 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.0 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.2 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.3 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.3 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.3 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.4 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.4 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from bcolz) (1.21.6)\n",
            "Building wheels for collected packages: bcolz\n",
            "  Building wheel for bcolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bcolz: filename=bcolz-1.2.1-cp37-cp37m-linux_x86_64.whl size=2643475 sha256=b3bb0184aea3d51ba1e1f2cb3b8b13338daa8ed243db21d204ec205971764a88\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/35/ca/9d914de345914e2446ea285170329f771b8abba2a00f7650bd\n",
            "Successfully built bcolz\n",
            "Installing collected packages: bcolz\n",
            "Successfully installed bcolz-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install bcolz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a3ac567",
      "metadata": {
        "id": "7a3ac567"
      },
      "source": [
        "# Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "adKAoZQWWzm7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adKAoZQWWzm7",
        "outputId": "245fb3d1-f2bd-466c-e003-c822787464d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tczYHi0oWuhZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tczYHi0oWuhZ",
        "outputId": "3bdf0b94-ce1b-4a60-fdce-4fd63fa75f3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "words = []\n",
        "idx = 0\n",
        "word2idx = {}\n",
        "glove_path = '/content/drive/MyDrive/505/project/CS505-final-project-main'\n",
        "vectors = bcolz.carray(np.zeros(1), rootdir=f'{glove_path}/6B.100.dat', mode='w')\n",
        "\n",
        "with open(f'{glove_path}/glove.6B.100d.txt', 'rb') as f:\n",
        "    for l in f:\n",
        "        line = l.decode().split()\n",
        "        word = line[0]\n",
        "        words.append(word)\n",
        "        word2idx[word] = idx\n",
        "        idx += 1\n",
        "        vect = np.array(line[1:]).astype(np.float)\n",
        "        vectors.append(vect)\n",
        "    \n",
        "vectors = bcolz.carray(vectors[1:].reshape((400000, 100)), rootdir=f'{glove_path}/6B.100.dat', mode='w')\n",
        "vectors.flush()\n",
        "pickle.dump(words, open(f'{glove_path}/6B.100_words.pkl', 'wb'))\n",
        "pickle.dump(word2idx, open(f'{glove_path}/6B.100_idx.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "96dd4274",
      "metadata": {
        "id": "96dd4274"
      },
      "outputs": [],
      "source": [
        "glove_path = '/content/drive/MyDrive/505/project/CS505-final-project-main'\n",
        "vectors = bcolz.open(f'{glove_path}/6B.100.dat')[:]\n",
        "words = pickle.load(open(f'{glove_path}/6B.100_words.pkl', 'rb'))\n",
        "words += ['<UNK>', '<s>', '</s>', 'PAD']\n",
        "vocab_list_glove = set(words)\n",
        "new_vecs = np.random.normal(loc=0.0, scale=.6, size=(4,100) )\n",
        "vectors = np.vstack((vectors, new_vecs))\n",
        "word2idx = pickle.load(open(f'{glove_path}/6B.100_idx.pkl', 'rb'))\n",
        "word2idx['<UNK>'] = 400000\n",
        "word2idx['<s>'] = 400001\n",
        "word2idx['</s>'] = 400002\n",
        "word2idx['PAD'] = 400003"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57fdvPMKB8N_",
      "metadata": {
        "id": "57fdvPMKB8N_"
      },
      "source": [
        "## Tweets pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "YRMqlKGAny0z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRMqlKGAny0z",
        "outputId": "cf277f30-02fd-45e2-c07c-3bdef63d1646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96562\n",
            "96562\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/505/project/'\n",
        "\n",
        "\n",
        "def read_json(filename: str):\n",
        "    with open(filename, \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Extract tweets and retweet numbers\n",
        "train = read_json(f'{path}/train.json')\n",
        "content = [item['text'] for item in train]\n",
        "retweet_num = [item['retweet_count'] for item in train]\n",
        "print(len(content))\n",
        "print(len(retweet_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "zEg9DfW93BO2",
      "metadata": {
        "id": "zEg9DfW93BO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5a9d68-ffbb-41c5-a5b9-43f17b25fd2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96562\n"
          ]
        }
      ],
      "source": [
        "# Clean tweets\n",
        "def pre_process(data):\n",
        "  clean_data = []\n",
        "  counts = 0\n",
        "  for line in data:\n",
        "    line = re.sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"url\", line) \n",
        "    line = re.sub(\"[^a-z@' ]\", \"\", line.lower()) \n",
        "    doc = nlp(line)\n",
        "    temp = []\n",
        "    for token in doc: \n",
        "      if token.text == 'url':\n",
        "        temp.append('<url>')\n",
        "      else:\n",
        "        temp.append(token.text)\n",
        "    \n",
        "    temp_2 = \" \".join(temp)  \n",
        "    text = re.sub(r\"@\\w+\", \"<user>\", temp_2)\n",
        "    clean_data.append(text)\n",
        "    counts += 1\n",
        "  print(counts)\n",
        "    \n",
        "\n",
        "  return clean_data\n",
        "\n",
        "tweets = pre_process(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "6qA5BXN13VBr",
      "metadata": {
        "id": "6qA5BXN13VBr"
      },
      "outputs": [],
      "source": [
        "# Save pre-process tweets\n",
        "file = open(f'{path}/train_clean_text.txt', \"w\")\n",
        "for item in tweets:\n",
        "    file.write(item + \"\\n\")\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "OhmJY9Gf3vWE",
      "metadata": {
        "id": "OhmJY9Gf3vWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ee0b5d-6824-4845-b236-a8913b145cd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96562\n"
          ]
        }
      ],
      "source": [
        "# Loading processed tweets\n",
        "#tweets = pd.read_csv(f'{path}/train_clean_text.txt', header = None)\n",
        "tweets = []\n",
        "with open(f'{path}/train_clean_text.txt', 'r') as f:\n",
        "    for line in f:\n",
        "      tweets.append(line[:-1])\n",
        "print(len(tweets))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Meta Data\n",
        "meta_data = pd.read_csv(f'{glove_path}/final_data.csv')\n",
        "meta = meta_data.iloc[:,1:]\n",
        "print(meta.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ulmrnLQgQzr",
        "outputId": "2ba5cb6a-2b30-4d8b-a43e-d1cc3662c56d"
      },
      "id": "_ulmrnLQgQzr",
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96562, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meta.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "bzbZFyeAmTmS",
        "outputId": "fd694108-5b94-43db-a28b-470631c0c756"
      },
      "id": "bzbZFyeAmTmS",
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_friends_count  user_followers_count      user_created_at  \\\n",
              "0               13723                120597  1247653266000000000   \n",
              "1               13723                120597  1247653266000000000   \n",
              "\n",
              "   favorite_count  user_statuses_count  photo  animated_gif  video  \n",
              "0               0               153810      0             0      0  \n",
              "1               0               153810      0             0      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb2d1ace-d5bd-471b-bec0-526ebb6a570c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_friends_count</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>user_created_at</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>user_statuses_count</th>\n",
              "      <th>photo</th>\n",
              "      <th>animated_gif</th>\n",
              "      <th>video</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13723</td>\n",
              "      <td>120597</td>\n",
              "      <td>1247653266000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>153810</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13723</td>\n",
              "      <td>120597</td>\n",
              "      <td>1247653266000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>153810</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb2d1ace-d5bd-471b-bec0-526ebb6a570c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb2d1ace-d5bd-471b-bec0-526ebb6a570c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb2d1ace-d5bd-471b-bec0-526ebb6a570c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meta['tweet'] = tweets\n",
        "print(meta.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APFN8uTCmKzb",
        "outputId": "f07e71c5-bbe6-4c09-eae6-35048ce0c58c"
      },
      "id": "APFN8uTCmKzb",
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96562, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(meta, retweet_num, test_size=0.2, random_state=42)\n",
        "print(len(X_train), len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm8Yp2ZqNJyI",
        "outputId": "5795a23e-474d-4e71-ef38-91d16d3e2332"
      },
      "id": "Wm8Yp2ZqNJyI",
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77249 19313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tweet = X_train.tweet\n",
        "X_test_tweet = X_test.tweet\n",
        "\n",
        "X_train_meta = X_train.iloc[:,:-1]\n",
        "X_test_meta = X_test.iloc[:,:-1]"
      ],
      "metadata": {
        "id": "ZzutBlDAmyXP"
      },
      "id": "ZzutBlDAmyXP",
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visalize the length of tweets\n",
        "# tweets length of 20 will be chosen\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "tweets_len = [len(x.split()) for x in tweets]\n",
        "pd.Series(tweets_len).hist()\n",
        "plt.show()\n",
        "pd.Series(tweets_len).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "xThK1Wfy4yVm",
        "outputId": "3845abcd-805f-4eb0-8f22-d91f6ca3f01f"
      },
      "id": "xThK1Wfy4yVm",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    96562.000000\n",
              "mean        15.556782\n",
              "std          5.810485\n",
              "min          0.000000\n",
              "25%         11.000000\n",
              "50%         17.000000\n",
              "75%         20.000000\n",
              "max         33.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building vocabulary for training data\n",
        "def word_count(data):\n",
        "  words_counter = Counter()\n",
        "  for line in data:\n",
        "    words =  line.split()\n",
        "    for w in words:\n",
        "      words_counter.update([w])\n",
        "  \n",
        "  words_counter_clean = {k:v for k,v in words_counter.items() if v > 1} # Removing the words that only appear once\n",
        "  sorted_words = sorted(words_counter_clean, key = words_counter_clean.get, reverse = True) # Sorting the words frequency in desc order\n",
        "  sorted_words = ['UNK','PAD', '<s>', '</s>' ] + sorted_words \n",
        "\n",
        "  return words_counter, words_counter_clean, sorted_words\n",
        "  \n",
        "words_counter, words_counter_clean, sorted_words = word_count(X_train_tweet)"
      ],
      "metadata": {
        "id": "uH6X4dcoOPLI"
      },
      "id": "uH6X4dcoOPLI",
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Not using slicing window padding\n",
        "def padding(data, seq_len):\n",
        "  sequences = []\n",
        "  for line in data:\n",
        "    line = f\"{'<s>'} {line} {'</s>'}\"\n",
        "    n_token = len(line.split())\n",
        "    \n",
        "    if n_token >= seq_len:\n",
        "      seq = line.split()[:seq_len] \n",
        "      sequences.append(\" \".join(seq))\n",
        "\n",
        "    else:\n",
        "      seq = line.split()\n",
        "      for i in range(seq_len - n_token):\n",
        "          seq.append('PAD')\n",
        "      sequences.append(\" \".join(seq))\n",
        "  return sequences\n",
        "\n",
        "X_train_pad = padding(X_train_tweet, 20)\n",
        "X_test_pad = padding(X_test_tweet, 20)"
      ],
      "metadata": {
        "id": "QbqatJDhN9hj"
      },
      "id": "QbqatJDhN9hj",
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace the words that only appear once with UNKNOWN\n",
        "def generate_sentence(data):\n",
        "  sequences = []\n",
        "  for line in data:\n",
        "    temp = []\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "      if word in sorted_words:\n",
        "        temp.append(word)\n",
        "      else:\n",
        "        temp.append('UNK')\n",
        "    sequences.append(\" \".join(temp))\n",
        "  return sequences\n",
        "\n",
        "X_train_final = generate_sentence(X_train_pad)\n",
        "X_test_final = generate_sentence(X_test_pad)"
      ],
      "metadata": {
        "id": "8P30CPRaOfyW"
      },
      "id": "8P30CPRaOfyW",
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ii7TYo3rL1-",
      "metadata": {
        "id": "6ii7TYo3rL1-"
      },
      "outputs": [],
      "source": [
        "# Using glove weights\n",
        "glove = {w: vectors[word2idx[w]] for w in words}\n",
        "matrix_len = len(sorted_words)\n",
        "weights_matrix = np.zeros((matrix_len, 100))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(sorted_words):\n",
        "  try: \n",
        "    weights_matrix[i] = glove[word] # if alr in the vocab, load its pre-trained word vector.\n",
        "    words_found += 1\n",
        "  except KeyError:\n",
        "    weights_matrix[i] = np.random.normal(scale=0.6, size=(100, ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "o54nmNt2w4sd",
      "metadata": {
        "id": "o54nmNt2w4sd"
      },
      "outputs": [],
      "source": [
        "# Using tweets training data vocabulary\n",
        "\n",
        "# Dictionaries to store the word to index mappings and vice versa\n",
        "word2idx = {o:i for i,o in enumerate(sorted_words)}\n",
        "idx2word = {i:o for i,o in enumerate(sorted_words)}\n",
        "\n",
        "\n",
        "# convert text sequences to integer sequences\n",
        "X_train_int = np.zeros((len(X_train_final), 20), dtype = int)\n",
        "for i, data in enumerate(X_train_final):\n",
        "  X_train_int[i] = [word2idx[w] for w in data.split()]\n",
        "\n",
        "X_test_int = np.zeros((len(X_test_final), 20), dtype = int)\n",
        "for i, data in enumerate(X_test_final):\n",
        "  X_test_int[i] = [word2idx[w] for w in data.split()]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert lists to numpy arrays\n",
        "X_train_int = np.array(X_train_int)\n",
        "y_train_int = np.array(y_train)\n",
        "\n",
        "X_test_int = np.array(X_test_int)\n",
        "y_test_int = np.array(y_test)"
      ],
      "metadata": {
        "id": "naTOqvd7Vg6m"
      },
      "id": "naTOqvd7Vg6m",
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(X_train_int), torch.from_numpy(y_train_int))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test_int), torch.from_numpy(y_test_int))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "rXCejXHbET3c"
      },
      "id": "rXCejXHbET3c",
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V526jI1Glo7o"
      },
      "id": "V526jI1Glo7o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5e5b8d40",
      "metadata": {
        "id": "5e5b8d40"
      },
      "source": [
        "# Neural Net\n",
        "\n",
        "### Retweet Network: Takes in a tweet as input, can use embedded version, and can any combination of bidirectional, LSTM, GRU, concatenates it with metadata vector, and uses a feedforward neural net with 1 hidden layer to perform a regression prediction on the retweet count. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96c224d1",
      "metadata": {
        "id": "96c224d1"
      },
      "source": [
        "#### Parameter custom_embeddings is either a tuple: (weight_matrix , none_trainable), or None.\n",
        "#### none_trainable is either True or False or Nothing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "  num_embeddings, embedding_dim = weights_matrix.shape\n",
        "  emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "  emb_layer.load_state_dict({'weight': torch.from_numpy(weights_matrix)})\n",
        "  if non_trainable:\n",
        "      emb_layer.weight.requires_grad = False\n",
        "  return emb_layer, num_embeddings, embedding_dim\n",
        "\n",
        "class RetweetNet(nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_state_sizes, meta_data_len, output_size, embedding_dim, hidden_dim, \n",
        "                 n_layers, drop_prob=0.5, custom_embeddings = None, bidirectional = False, GRU = False):\n",
        "    super().__init__()\n",
        "    self.GRU_val = GRU\n",
        "    self.bidirectional = bidirectional\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "        \n",
        "    if custom_embeddings is None: \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    else: \n",
        "        assert len(custom_embeddings) == 2 and isinstance(custom_embeddings, tuple), \"custom embeddings must be of form: (weight_matrix, non_trainable)\"\n",
        "        weights_matrix, non_trainable = custom_embeddings\n",
        "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, non_trainable)\n",
        "        \n",
        "    if GRU == False: \n",
        "        self.Gate = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True, bidirectional = bidirectional)\n",
        "    else: \n",
        "        self.Gate = nn.GRU(embedding_dim, hidden_dim, n_layers, \n",
        "                              dropout=drop_prob, batch_first=True, bidirectional = bidirectional)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.fc1 = nn.Linear(hidden_dim, hidden_state_sizes[0])\n",
        "    self.relu = nn.RELU()\n",
        "        \n",
        "    #hidden_state_sizes[0] is the size of the output of lstm \n",
        "    self.fc2 = nn.Linear(hidden_state_sizes[0] + meta_data_len, hidden_state_sizes[1])\n",
        "        \n",
        "    #hidden_state_sizes[1] is the size of the first and only hidden layer\n",
        "    self.fc3 = nn.Linear(hidden_state_sizes[1], 1)\n",
        "\n",
        "        \n",
        "  def forward(self, x, meta_data, hidden):\n",
        "    batch_size = x.size(0)\n",
        "    x = x.long()\n",
        "    embeds = self.embedding(x)\n",
        "    gru_out, hidden = self.Gate(embeds, hidden)\n",
        "    gru_out = gru_out.contiguous().view(-1, self.hidden_dim)\n",
        "    \n",
        "    out = self.dropout(gru_out)\n",
        "    out = self.fc1(out)\n",
        "    out = out.view(batch_size, -1)\n",
        "    out = out[:,-1] \n",
        "    meta_data = meta_data.view(batch_size, -1)\n",
        "        \n",
        "    # combine hidden state and meta_data\n",
        "    out = torch.cat((out, meta_data), dim = 1) #meta_data is of shape (batch_size, -1)\n",
        "        \n",
        "    out = self.fc2(out)\n",
        "        \n",
        "    # applying dropout before relu since relu already sets some neurons to 0\n",
        "    out = self.dropout(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc3(out)\n",
        "        \n",
        "    return out, hidden\n",
        "    \n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    n = 1\n",
        "    if self.bidirectional == True: \n",
        "      n = 2\n",
        "    if self.GRU_val == False:\n",
        "      return (weight.new(self.n_layers * n, batch_size, self.hidden_dim).zero_().to('cuda'),\n",
        "              weight.new(self.n_layers * n, batch_size, self.hidden_dim).zero_().to('cuda'))\n",
        "    else:\n",
        "      return  weight.new(self.n_layers * n, batch_size, self.hidden_dim).zero_().to('cuda')\n",
        "\n",
        "\n",
        "def train_retweet_predictor(model, epochs = 2,print_every = 1000, clip = 5, valid_loss_min = np.Inf, lr=0.005, batch_size = 400, device = 'cuda', GRU = False, weight_decay = 1e-5): \n",
        "  counter = 0\n",
        "  model.train()\n",
        "    \n",
        "  criterion = nn.MSELoss()\n",
        "    \n",
        "  # weight decay is the l2 regularization penalty \n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    \n",
        "  for i in range(epochs):\n",
        "    h = model.init_hidden(batch_size)\n",
        "\n",
        "  for inputs, labels in train_loader:\n",
        "    counter += 1\n",
        "    if GRU == False: \n",
        "      h = tuple([each.data for each in h])\n",
        "    else:\n",
        "      h = h.data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    model.zero_grad()\n",
        "    output, h = model(inputs, h)\n",
        "    loss = criterion(output.squeeze(), labels.float())\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "    print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "          \"Step: {}...\".format(counter),\n",
        "          \"Loss: {:.6f}...\".format(loss.item()))\n",
        "          \n",
        "def error_retweet_predictor(model, batch_size = 359, device = 'cuda', GRU = False): \n",
        "  test_losses = []\n",
        "  num_correct = []\n",
        "  model.cuda()\n",
        "\n",
        "  h = model.init_hidden(batch_size)\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  model.eval()\n",
        "  for inputs, labels in test_loader:\n",
        "    if GRU == True: \n",
        "      h = h.data\n",
        "    else: \n",
        "      h = tuple([each.data for each in h])\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    output, h = model(inputs, h)\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    pred = torch.round(output.squeeze())\n",
        "        \n",
        "    errors = torch.sum(torch.square(pred - labels.float().view_as(pred)), axis= 1)/(predicted_x.size()[0]\n",
        "    num_correct.append(np.squeeze(errors.cpu().numpy()))    \n",
        "  print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "  print(\"Test accuracy: {:.3f}%\".format(np.mean(num_correct)))"
      ],
      "metadata": {
        "id": "xGLQtrqBeoOr"
      },
      "id": "xGLQtrqBeoOr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Retweet Model 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}