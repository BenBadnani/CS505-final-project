{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ghIfS47AVBd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghIfS47AVBd1",
        "outputId": "ae5e7776-4b70-49ed-90c1-fcc767fe2eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bcolz\n",
            "  Downloading bcolz-1.2.1.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from bcolz) (1.21.6)\n",
            "Building wheels for collected packages: bcolz\n",
            "  Building wheel for bcolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bcolz: filename=bcolz-1.2.1-cp37-cp37m-linux_x86_64.whl size=2641567 sha256=c41d05a2279bf0d88062685084ae65019d55af390f46cbce641e76587138f6fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/35/ca/9d914de345914e2446ea285170329f771b8abba2a00f7650bd\n",
            "Successfully built bcolz\n",
            "Installing collected packages: bcolz\n",
            "Successfully installed bcolz-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install bcolz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96da3e8a",
      "metadata": {
        "id": "96da3e8a"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from google.colab import files\n",
        "import bcolz\n",
        "import pickle\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import csv\n",
        "import json\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import spacy\n",
        "import re\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "#stopwords = nlp.Defaults.stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adKAoZQWWzm7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adKAoZQWWzm7",
        "outputId": "1bbac9a8-e958-472f-dfc0-ef3618927d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YRMqlKGAny0z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRMqlKGAny0z",
        "outputId": "2e1996d8-ad48-433d-cfb1-68ff8ac4f20b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96562, 9)\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/505/project/'\n",
        "\n",
        "data = pd.read_csv(f'{path}/data.csv')\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_count = []\n",
        "for item in data['tweet']:\n",
        "  n = len(str(item).split())\n",
        "  tweets_count.append(n)\n",
        "\n",
        "data['tweet_len'] = tweets_count\n",
        "len(tweets_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orG2qQox86O-",
        "outputId": "6890e092-674f-408a-8d51-5ee2bde69ee1"
      },
      "id": "orG2qQox86O-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96562"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "pd.Series(tweets_count).hist()\n",
        "plt.show()\n",
        "pd.Series(tweets_count).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "ekyN8dyBqn7I",
        "outputId": "46e6d20a-3b90-402f-a51d-0ef6ff1a4ffb"
      },
      "id": "ekyN8dyBqn7I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAU1ElEQVR4nO3db4xd9Z3f8fdnbUgQ7MawpCNk3JoWa1cEd0kyAlYbVUOiBUMemEgUgWgwWXYdaUFKtH4QJ1IFG4JEqiWpUBNaR1gxbTYOyp9iBWepRRmlecDfhGAMpcwSI2wRo435k0lSosl+++D+Zns9zHjGM+O5c5z3S7q6537P75zzvcd35jPn3HOvU1VIkn67/c6gG5AkDZ5hIEkyDCRJhoEkCcNAkgSsHHQD83XmmWfW2rVrj6j94he/4NRTTx1MQ4vA/geny71Dt/vvcu/Qvf6ffPLJf6iqd0+tdzYM1q5dyxNPPHFEbXR0lJGRkcE0tAjsf3C63Dt0u/8u9w7d6z/JS9PVPU0kSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQ6/Alkablau/WBJd/mlvUT3LD1Afbf8eEl37ZODB4ZSJIMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CSxBzCIMk7kzyW5MdJ9iX561Y/J8mjScaSfCPJya3+jvZ4rM1f27euT7f680ku66tvaLWxJFsX/2lKko5mLkcGbwEfrKo/Ai4ANiS5GPg88MWqOhd4Dbixjb8ReK3Vv9jGkeQ84BrgPcAG4MtJViRZAXwJuBw4D7i2jZUkLZFZw6B6xtvDk9qtgA8C32z1HcCVbXpje0yb/6EkafWdVfVWVf0EGAMubLexqnqxqn4N7GxjJUlLZE7fWtr+en8SOJfeX/F/D7xeVRNtyAFgdZteDbwMUFUTSd4Afr/VH+lbbf8yL0+pXzRDH5uBzQBDQ0OMjo4eMX98fPxttS6x/8FZzN63rJ+YfdAiGzqlt90u7v8uv26g+/1PmlMYVNVvgAuSrAK+A/zhce1q5j62AdsAhoeHa2Rk5Ij5o6OjTK11if0PzmL2fsOAvsL6zr0r2X/dyJJve6G6/LqB7vc/6ZiuJqqq14GHgT8GViWZDJOzgYNt+iCwBqDNfxfws/76lGVmqkuSlshcriZ6dzsiIMkpwJ8Cz9ELhavasE3A/W16V3tMm/8/q6pa/Zp2tdE5wDrgMeBxYF27Oulkem8y71qMJydJmpu5nCY6C9jR3jf4HeC+qvpukmeBnUk+B/wIuKeNvwf4r0nGgMP0frlTVfuS3Ac8C0wAN7XTTyS5GXgQWAFsr6p9i/YMJUmzmjUMqupp4L3T1F+kdyXQ1Pr/Bf7tDOu6Hbh9mvpuYPcc+pUkHQd+AlmSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJDGHMEiyJsnDSZ5Nsi/JJ1r91iQHkzzVblf0LfPpJGNJnk9yWV99Q6uNJdnaVz8nyaOt/o0kJy/2E5UkzWwuRwYTwJaqOg+4GLgpyXlt3her6oJ22w3Q5l0DvAfYAHw5yYokK4AvAZcD5wHX9q3n821d5wKvATcu0vOTJM3BrGFQVa9U1Q/b9M+B54DVR1lkI7Czqt6qqp8AY8CF7TZWVS9W1a+BncDGJAE+CHyzLb8DuHK+T0iSdOxSVXMfnKwFvg+cD/wVcAPwJvAEvaOH15L8J+CRqvpvbZl7gO+1VWyoqj9v9Y8CFwG3tvHntvoa4HtVdf40298MbAYYGhp6/86dO4+YPz4+zmmnnTbn57Pc2P/gLGbvew++sSjrORZDp8ChX8H61e9a8m0vVJdfN9C9/i+55JInq2p4an3lXFeQ5DTgW8Anq+rNJHcDtwHV7u8E/myR+p1WVW0DtgEMDw/XyMjIEfNHR0eZWusS+x+cxez9hq0PLMp6jsWW9RPcuXcl+68bWfJtL1SXXzfQ/f4nzSkMkpxELwi+VlXfBqiqQ33zvwJ8tz08CKzpW/zsVmOG+s+AVUlWVtXElPGSpCUwl6uJAtwDPFdVX+irn9U37CPAM216F3BNknckOQdYBzwGPA6sa1cOnUzvTeZd1TtP9TBwVVt+E3D/wp6WJOlYzOXI4E+AjwJ7kzzVap+hdzXQBfROE+0HPg5QVfuS3Ac8S+9KpJuq6jcASW4GHgRWANural9b36eAnUk+B/yIXvhIkpbIrGFQVT8AMs2s3UdZ5nbg9mnqu6dbrqpepHe1kSRpAPwEsiTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJYg5hkGRNkoeTPJtkX5JPtPoZSfYkeaHdn97qSXJXkrEkTyd5X9+6NrXxLyTZ1Fd/f5K9bZm7kuR4PFlJ0vTmcmQwAWypqvOAi4GbkpwHbAUeqqp1wEPtMcDlwLp22wzcDb3wAG4BLgIuBG6ZDJA25i/6ltuw8KcmSZqrWcOgql6pqh+26Z8DzwGrgY3AjjZsB3Blm94I3Fs9jwCrkpwFXAbsqarDVfUasAfY0Ob9XlU9UlUF3Nu3LknSEjim9wySrAXeCzwKDFXVK23WT4GhNr0aeLlvsQOtdrT6gWnqkqQlsnKuA5OcBnwL+GRVvdl/Wr+qKkkdh/6m9rCZ3qknhoaGGB0dPWL++Pj422pdYv+Ds5i9b1k/sSjrORZDp/S228X93+XXDXS//0lzCoMkJ9ELgq9V1bdb+VCSs6rqlXaq59VWPwis6Vv87FY7CIxMqY+2+tnTjH+bqtoGbAMYHh6ukZGRI+aPjo4ytdYl9j84i9n7DVsfWJT1HIst6ye4c+9K9l83suTbXqguv26g+/1PmsvVRAHuAZ6rqi/0zdoFTF4RtAm4v69+fbuq6GLgjXY66UHg0iSntzeOLwUebPPeTHJx29b1feuSJC2BuRwZ/AnwUWBvkqda7TPAHcB9SW4EXgKubvN2A1cAY8AvgY8BVNXhJLcBj7dxn62qw236L4GvAqcA32s3SdISmTUMquoHwEzX/X9omvEF3DTDurYD26epPwGcP1svkqTjw08gS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkoCVg25A0uJZu/WBgWx3/x0fHsh2tXg8MpAkzR4GSbYneTXJM321W5McTPJUu13RN+/TScaSPJ/ksr76hlYbS7K1r35Okkdb/RtJTl7MJyhJmt1cjgy+CmyYpv7Fqrqg3XYDJDkPuAZ4T1vmy0lWJFkBfAm4HDgPuLaNBfh8W9e5wGvAjQt5QpKkYzdrGFTV94HDc1zfRmBnVb1VVT8BxoAL222sql6sql8DO4GNSQJ8EPhmW34HcOUxPgdJ0gIt5D2Dm5M83U4jnd5qq4GX+8YcaLWZ6r8PvF5VE1PqkqQlNN+rie4GbgOq3d8J/NliNTWTJJuBzQBDQ0OMjo4eMX98fPxttS6x/8FZzN63rJ+YfdAiGzplMNudtJB91+XXDXS//0nzCoOqOjQ5neQrwHfbw4PAmr6hZ7caM9R/BqxKsrIdHfSPn26724BtAMPDwzUyMnLE/NHRUabWusT+B2cxe79hAJd3blk/wZ17B3el+P7rRua9bJdfN9D9/ifN6zRRkrP6Hn4EmLzSaBdwTZJ3JDkHWAc8BjwOrGtXDp1M703mXVVVwMPAVW35TcD98+lJkjR/s/4pkeTrwAhwZpIDwC3ASJIL6J0m2g98HKCq9iW5D3gWmABuqqrftPXcDDwIrAC2V9W+tolPATuTfA74EXDPoj07SdKczBoGVXXtNOUZf2FX1e3A7dPUdwO7p6m/SO9qI0nSgPgJZEmSYSBJMgwkSRgGkiQMA0kS/n8GOoEdy3f7b1k/MZAPi0nLhUcGkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJDGHMEiyPcmrSZ7pq52RZE+SF9r96a2eJHclGUvydJL39S2zqY1/Icmmvvr7k+xty9yVJIv9JCVJRzeXI4OvAhum1LYCD1XVOuCh9hjgcmBdu20G7oZeeAC3ABcBFwK3TAZIG/MXfctN3ZYk6TibNQyq6vvA4SnljcCONr0DuLKvfm/1PAKsSnIWcBmwp6oOV9VrwB5gQ5v3e1X1SFUVcG/fuiRJS2TlPJcbqqpX2vRPgaE2vRp4uW/cgVY7Wv3ANPVpJdlM74iDoaEhRkdHj5g/Pj7+tlqX2P/i2rJ+Ys5jh045tvHLzaD7X8i/+3J73Ryrrvc/ab5h8E+qqpLUYjQzh21tA7YBDA8P18jIyBHzR0dHmVrrEvtfXDdsfWDOY7esn+DOvQv+cRiYQfe//7qReS+73F43x6rr/U+a76vnUJKzquqVdqrn1VY/CKzpG3d2qx0ERqbUR1v97GnG6wSx9hh+IUsanPleWroLmLwiaBNwf1/9+nZV0cXAG+100oPApUlOb28cXwo82Oa9meTidhXR9X3rkiQtkVmPDJJ8nd5f9WcmOUDvqqA7gPuS3Ai8BFzdhu8GrgDGgF8CHwOoqsNJbgMeb+M+W1WTb0r/Jb0rlk4BvtduWmRL8Rf6lvUTx3RqRtLyMWsYVNW1M8z60DRjC7hphvVsB7ZPU38COH+2PiRJx4+fQJYkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJLEIvx/Bpq72b4szi96kzQoHhlIkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJYoFhkGR/kr1JnkryRKudkWRPkhfa/emtniR3JRlL8nSS9/WtZ1Mb/0KSTQt7SpKkY7UYRwaXVNUFVTXcHm8FHqqqdcBD7THA5cC6dtsM3A298ABuAS4CLgRumQwQSdLSOB6niTYCO9r0DuDKvvq91fMIsCrJWcBlwJ6qOlxVrwF7gA3HoS9J0gxSVfNfOPkJ8BpQwH+pqm1JXq+qVW1+gNeqalWS7wJ3VNUP2ryHgE8BI8A7q+pzrf7vgV9V1d9Ms73N9I4qGBoaev/OnTuPmD8+Ps5pp502a997D74xz2d8fA2dAod+Negu5q/L/Xe5dxh8/+tXv2vey87153a56lr/l1xyyZN9Z3L+yUL/P4MPVNXBJP8M2JPkf/fPrKpKMv+0maKqtgHbAIaHh2tkZOSI+aOjo0ytTWe5/p8BW9ZPcOfe7v4XE13uv8u9w+D733/dyLyXnevP7XLV9f4nLeg0UVUdbPevAt+hd87/UDv9Q7t/tQ0/CKzpW/zsVpupLklaIvMOgySnJvndyWngUuAZYBcweUXQJuD+Nr0LuL5dVXQx8EZVvQI8CFya5PT2xvGlrSZJWiILOa4cAr7Te1uAlcDfVtXfJXkcuC/JjcBLwNVt/G7gCmAM+CXwMYCqOpzkNuDxNu6zVXV4AX1Jko7RvMOgql4E/mia+s+AD01TL+CmGda1Hdg+314kSQvjJ5AlSYaBJMkwkCSx8M8ZSBJrF/DZnS3rJ+b92Z/9d3x43tvVkTwykCQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJLEMgqDJBuSPJ9kLMnWQfcjSb9NVg66AYAkK4AvAX8KHAAeT7Krqp4dbGeSlrO1Wx8Y2Lb33/HhgW37eFguRwYXAmNV9WJV/RrYCWwccE+S9FsjVTXoHkhyFbChqv68Pf4ocFFV3Txl3GZgc3v4B8DzU1Z1JvAPx7nd48n+B6fLvUO3++9y79C9/v9FVb17anFZnCaaq6raBmybaX6SJ6pqeAlbWlT2Pzhd7h263X+Xe4fu9z9puZwmOgis6Xt8dqtJkpbAcgmDx4F1Sc5JcjJwDbBrwD1J0m+NZXGaqKomktwMPAisALZX1b55rGrGU0gdYf+D0+Xeodv9d7l36H7/wDJ5A1mSNFjL5TSRJGmADANJ0okTBl3/Oosk+5PsTfJUkicG3c/RJNme5NUkz/TVzkiyJ8kL7f70QfZ4NDP0f2uSg23/P5XkikH2OJMka5I8nOTZJPuSfKLVO7H/j9L/st//Sd6Z5LEkP269/3Wrn5Pk0fa75xvtIpjOOSHeM2hfZ/F/6Ps6C+DaLn2dRZL9wHBVLfsPryT5N8A4cG9Vnd9q/wE4XFV3tDA+vao+Ncg+ZzJD/7cC41X1N4PsbTZJzgLOqqofJvld4EngSuAGOrD/j9L/1Szz/Z8kwKlVNZ7kJOAHwCeAvwK+XVU7k/xn4MdVdfcge52PE+XIwK+zWEJV9X3g8JTyRmBHm95B7wd8WZqh/06oqleq6odt+ufAc8BqOrL/j9L/slc94+3hSe1WwAeBb7b6st33szlRwmA18HLf4wN05AXWp4D/keTJ9rUbXTNUVa+06Z8CQ4NsZp5uTvJ0O420LE+z9EuyFngv8Cgd3P9T+ocO7P8kK5I8BbwK7AH+Hni9qibakC7+7gFOnDA4EXygqt4HXA7c1E5ldFL1zj127fzj3cC/Ai4AXgHuHGw7R5fkNOBbwCer6s3+eV3Y/9P034n9X1W/qaoL6H1LwoXAHw64pUVzooRB57/OoqoOtvtXge/Qe6F1yaF2PnjyvPCrA+7nmFTVofaD/o/AV1jG+7+dr/4W8LWq+nYrd2b/T9d/l/Y/QFW9DjwM/DGwKsnkB3g797tn0okSBp3+Ooskp7Y300hyKnAp8MzRl1p2dgGb2vQm4P4B9nLMJn+RNh9hme7/9ibmPcBzVfWFvlmd2P8z9d+F/Z/k3UlWtelT6F2w8hy9ULiqDVu2+342J8TVRADtUrT/yP//OovbB9zSnCX5l/SOBqD3FSF/u5z7T/J1YITeV/ceAm4B/jtwH/DPgZeAq6tqWb5JO0P/I/ROURSwH/h43zn4ZSPJB4D/BewF/rGVP0PvvPuy3/9H6f9alvn+T/Kv6b1BvILeH9L3VdVn28/vTuAM4EfAv6uqtwbX6fycMGEgSZq/E+U0kSRpAQwDSZJhIEkyDCRJGAaSJAwDSRKGgSQJ+H+faYWcGJzZUAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    96562.000000\n",
              "mean        15.556803\n",
              "std          5.810431\n",
              "min          1.000000\n",
              "25%         11.000000\n",
              "50%         17.000000\n",
              "75%         20.000000\n",
              "max         33.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print('video:' , Counter(data.video))\n",
        "print('photo:' , Counter(data.photo))\n",
        "print('animated_gif:', Counter(data.animated_gif))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMjvJK1kBTWN",
        "outputId": "910cebda-c3c4-4d44-87ba-45dcd23d05be"
      },
      "id": "zMjvJK1kBTWN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "video: Counter({0: 96562})\n",
            "photo: Counter({0: 88522, 1: 8040})\n",
            "animated_gif: Counter({0: 96562})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(data.tweet_len).most_common()[:-10-1:-1] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhDG1TVUqgqv",
        "outputId": "f0bda512-1e0a-478f-cc31-3b2a9fbeec93"
      },
      "id": "zhDG1TVUqgqv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(33, 1),\n",
              " (32, 1),\n",
              " (31, 5),\n",
              " (30, 7),\n",
              " (29, 34),\n",
              " (28, 70),\n",
              " (27, 158),\n",
              " (1, 403),\n",
              " (26, 432),\n",
              " (25, 977)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data['tweet_len'] > 1]\n",
        "needed = ['user_friends_count', 'user_followers_count', 'favorite_count','user_statuses_count', 'tweet','retweets']\n",
        "df = data[needed]\n",
        "print(df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVOX0u-4vq2j",
        "outputId": "53af6baa-14e8-440e-d60c-18e761a1dcc0"
      },
      "id": "OVOX0u-4vq2j",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96159, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(df.retweets).most_common(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4GXZzYgDHnd",
        "outputId": "3118a571-02d5-4922-9d1e-0d9dd4d73ed6"
      },
      "id": "F4GXZzYgDHnd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 64978),\n",
              " (1, 8143),\n",
              " (2, 4240),\n",
              " (3, 3280),\n",
              " (4, 2523),\n",
              " (5, 2007),\n",
              " (6, 1506),\n",
              " (7, 1226),\n",
              " (8, 932),\n",
              " (9, 801)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = pd.DataFrame.from_dict(Counter(df.retweets), orient='index').reset_index()\n",
        "temp.columns = ['num', 'count']\n",
        "temp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXXxArTMOKzb",
        "outputId": "8e7e0203-d9dd-4ad5-d81e-667a7e470b7c"
      },
      "id": "yXXxArTMOKzb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.boxplot(column=['count']) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "qFct23G0rlRU",
        "outputId": "f793f3be-be38-471a-aadd-c16eaa4e934f"
      },
      "id": "qFct23G0rlRU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3c7721d090>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_0 = df[df['retweets'] == 0]\n",
        "class_1 = df[df['retweets'] == 1]\n",
        "class_not01 = df[df['retweets'] > 1]"
      ],
      "metadata": {
        "id": "TvUnl5sIE6at"
      },
      "id": "TvUnl5sIE6at",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_0_under = class_0.sample(4000)\n",
        "class_1_under = class_1.sample(4000)\n",
        "df2 = pd.concat([class_0_under, class_1_under, class_not01], axis=0)"
      ],
      "metadata": {
        "id": "hC_G9cc4FOY-"
      },
      "id": "hC_G9cc4FOY-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['retweets'] >50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "blqVp8iEGMmD",
        "outputId": "0e9475db-b989-4b68-8cbe-91ac2681f687"
      },
      "id": "blqVp8iEGMmD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       user_friends_count  user_followers_count  favorite_count  \\\n",
              "1633                13723                120597             289   \n",
              "2735                 6683                 99633             103   \n",
              "2739                 6683                 99633             106   \n",
              "2758                 6683                 99633             153   \n",
              "2761                 6683                 99633             671   \n",
              "...                   ...                   ...             ...   \n",
              "94514               26139                217532             294   \n",
              "95530               26139                217530             352   \n",
              "95888               26139                217530               0   \n",
              "96158               26139                217530             237   \n",
              "96414               26139                217530             339   \n",
              "\n",
              "       user_statuses_count                                              tweet  \\\n",
              "1633                153810  a hattrick on debut for the sbproteasyoungest ...   \n",
              "2735                152258  make sure you do n't miss the first ever intel...   \n",
              "2739                152258  join us as we celebrate our brand launch with ...   \n",
              "2758                152258  hello mzansi meet the new us and our new logo ...   \n",
              "2761                152258  when the time came to reimagine a new absa we ...   \n",
              "...                    ...                                                ...   \n",
              "94514               181091  keep snapping and sharing with telkomfam we se...   \n",
              "95530               181091  welcome the all new <user> note including a   ...   \n",
              "95888               181091  rt <user> when king b opens his mouthmeidolssa...   \n",
              "96158               181091  are you a game changer the galaxy note   is he...   \n",
              "96414               181091  this months competition is for you ladies who ...   \n",
              "\n",
              "       retweets  cat  \n",
              "1633         87    7  \n",
              "2735         61    7  \n",
              "2739         54    7  \n",
              "2758        103    7  \n",
              "2761        230    7  \n",
              "...         ...  ...  \n",
              "94514        70    7  \n",
              "95530        71    7  \n",
              "95888        68    7  \n",
              "96158        80    7  \n",
              "96414        60    7  \n",
              "\n",
              "[841 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4182a840-f3b4-4c8c-a1ae-7557c8ee4fe0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_friends_count</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>user_statuses_count</th>\n",
              "      <th>tweet</th>\n",
              "      <th>retweets</th>\n",
              "      <th>cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1633</th>\n",
              "      <td>13723</td>\n",
              "      <td>120597</td>\n",
              "      <td>289</td>\n",
              "      <td>153810</td>\n",
              "      <td>a hattrick on debut for the sbproteasyoungest ...</td>\n",
              "      <td>87</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2735</th>\n",
              "      <td>6683</td>\n",
              "      <td>99633</td>\n",
              "      <td>103</td>\n",
              "      <td>152258</td>\n",
              "      <td>make sure you do n't miss the first ever intel...</td>\n",
              "      <td>61</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2739</th>\n",
              "      <td>6683</td>\n",
              "      <td>99633</td>\n",
              "      <td>106</td>\n",
              "      <td>152258</td>\n",
              "      <td>join us as we celebrate our brand launch with ...</td>\n",
              "      <td>54</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2758</th>\n",
              "      <td>6683</td>\n",
              "      <td>99633</td>\n",
              "      <td>153</td>\n",
              "      <td>152258</td>\n",
              "      <td>hello mzansi meet the new us and our new logo ...</td>\n",
              "      <td>103</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2761</th>\n",
              "      <td>6683</td>\n",
              "      <td>99633</td>\n",
              "      <td>671</td>\n",
              "      <td>152258</td>\n",
              "      <td>when the time came to reimagine a new absa we ...</td>\n",
              "      <td>230</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94514</th>\n",
              "      <td>26139</td>\n",
              "      <td>217532</td>\n",
              "      <td>294</td>\n",
              "      <td>181091</td>\n",
              "      <td>keep snapping and sharing with telkomfam we se...</td>\n",
              "      <td>70</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95530</th>\n",
              "      <td>26139</td>\n",
              "      <td>217530</td>\n",
              "      <td>352</td>\n",
              "      <td>181091</td>\n",
              "      <td>welcome the all new &lt;user&gt; note including a   ...</td>\n",
              "      <td>71</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95888</th>\n",
              "      <td>26139</td>\n",
              "      <td>217530</td>\n",
              "      <td>0</td>\n",
              "      <td>181091</td>\n",
              "      <td>rt &lt;user&gt; when king b opens his mouthmeidolssa...</td>\n",
              "      <td>68</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96158</th>\n",
              "      <td>26139</td>\n",
              "      <td>217530</td>\n",
              "      <td>237</td>\n",
              "      <td>181091</td>\n",
              "      <td>are you a game changer the galaxy note   is he...</td>\n",
              "      <td>80</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96414</th>\n",
              "      <td>26139</td>\n",
              "      <td>217530</td>\n",
              "      <td>339</td>\n",
              "      <td>181091</td>\n",
              "      <td>this months competition is for you ladies who ...</td>\n",
              "      <td>60</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>841 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4182a840-f3b4-4c8c-a1ae-7557c8ee4fe0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4182a840-f3b4-4c8c-a1ae-7557c8ee4fe0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4182a840-f3b4-4c8c-a1ae-7557c8ee4fe0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(df['retweets'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9YzjE7sBSFs",
        "outputId": "7445a0d2-465a-4d7a-a95a-1deff7dc60e0"
      },
      "id": "f9YzjE7sBSFs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 64978,\n",
              "         1: 8143,\n",
              "         2: 4240,\n",
              "         3: 3280,\n",
              "         4: 2523,\n",
              "         5: 2007,\n",
              "         6: 1506,\n",
              "         7: 1226,\n",
              "         8: 932,\n",
              "         9: 801,\n",
              "         10: 622,\n",
              "         11: 556,\n",
              "         12: 468,\n",
              "         13: 394,\n",
              "         14: 309,\n",
              "         15: 297,\n",
              "         16: 297,\n",
              "         17: 213,\n",
              "         18: 197,\n",
              "         19: 179,\n",
              "         20: 159,\n",
              "         21: 148,\n",
              "         22: 140,\n",
              "         23: 135,\n",
              "         24: 114,\n",
              "         25: 114,\n",
              "         26: 91,\n",
              "         27: 95,\n",
              "         28: 81,\n",
              "         29: 92,\n",
              "         30: 71,\n",
              "         31: 81,\n",
              "         32: 69,\n",
              "         33: 79,\n",
              "         34: 55,\n",
              "         35: 58,\n",
              "         36: 67,\n",
              "         37: 52,\n",
              "         38: 45,\n",
              "         39: 45,\n",
              "         40: 48,\n",
              "         41: 37,\n",
              "         42: 33,\n",
              "         43: 26,\n",
              "         44: 44,\n",
              "         45: 33,\n",
              "         46: 28,\n",
              "         47: 28,\n",
              "         48: 33,\n",
              "         49: 24,\n",
              "         50: 25,\n",
              "         51: 25,\n",
              "         52: 19,\n",
              "         53: 24,\n",
              "         54: 17,\n",
              "         55: 15,\n",
              "         56: 27,\n",
              "         57: 26,\n",
              "         58: 18,\n",
              "         59: 21,\n",
              "         60: 16,\n",
              "         61: 20,\n",
              "         62: 11,\n",
              "         63: 15,\n",
              "         64: 26,\n",
              "         65: 15,\n",
              "         66: 11,\n",
              "         67: 8,\n",
              "         68: 17,\n",
              "         69: 14,\n",
              "         70: 10,\n",
              "         71: 15,\n",
              "         72: 11,\n",
              "         73: 8,\n",
              "         74: 11,\n",
              "         75: 12,\n",
              "         76: 12,\n",
              "         77: 12,\n",
              "         78: 5,\n",
              "         79: 5,\n",
              "         80: 5,\n",
              "         81: 6,\n",
              "         82: 3,\n",
              "         83: 5,\n",
              "         84: 6,\n",
              "         85: 8,\n",
              "         86: 6,\n",
              "         87: 10,\n",
              "         88: 9,\n",
              "         89: 6,\n",
              "         90: 7,\n",
              "         92: 5,\n",
              "         93: 4,\n",
              "         94: 1,\n",
              "         95: 5,\n",
              "         96: 4,\n",
              "         97: 1,\n",
              "         98: 5,\n",
              "         99: 1,\n",
              "         100: 4,\n",
              "         101: 6,\n",
              "         102: 3,\n",
              "         103: 4,\n",
              "         104: 5,\n",
              "         105: 2,\n",
              "         106: 2,\n",
              "         107: 2,\n",
              "         108: 1,\n",
              "         109: 2,\n",
              "         110: 3,\n",
              "         111: 2,\n",
              "         112: 2,\n",
              "         113: 6,\n",
              "         114: 2,\n",
              "         116: 2,\n",
              "         119: 1,\n",
              "         120: 3,\n",
              "         121: 3,\n",
              "         122: 1,\n",
              "         123: 1,\n",
              "         124: 1,\n",
              "         125: 1,\n",
              "         126: 2,\n",
              "         127: 1,\n",
              "         128: 2,\n",
              "         129: 1,\n",
              "         130: 6,\n",
              "         131: 1,\n",
              "         132: 2,\n",
              "         133: 2,\n",
              "         135: 5,\n",
              "         136: 1,\n",
              "         137: 3,\n",
              "         138: 1,\n",
              "         139: 2,\n",
              "         140: 3,\n",
              "         141: 3,\n",
              "         142: 2,\n",
              "         144: 1,\n",
              "         146: 1,\n",
              "         147: 1,\n",
              "         148: 1,\n",
              "         149: 1,\n",
              "         150: 3,\n",
              "         151: 2,\n",
              "         153: 1,\n",
              "         154: 2,\n",
              "         155: 2,\n",
              "         156: 1,\n",
              "         157: 2,\n",
              "         158: 1,\n",
              "         159: 2,\n",
              "         160: 1,\n",
              "         161: 1,\n",
              "         162: 4,\n",
              "         165: 3,\n",
              "         167: 1,\n",
              "         168: 1,\n",
              "         170: 2,\n",
              "         171: 1,\n",
              "         172: 2,\n",
              "         174: 1,\n",
              "         175: 1,\n",
              "         176: 1,\n",
              "         177: 1,\n",
              "         178: 2,\n",
              "         179: 1,\n",
              "         183: 2,\n",
              "         187: 1,\n",
              "         188: 1,\n",
              "         189: 2,\n",
              "         190: 1,\n",
              "         193: 1,\n",
              "         194: 1,\n",
              "         195: 1,\n",
              "         196: 2,\n",
              "         198: 1,\n",
              "         201: 2,\n",
              "         206: 1,\n",
              "         207: 2,\n",
              "         208: 1,\n",
              "         209: 1,\n",
              "         211: 1,\n",
              "         217: 1,\n",
              "         218: 1,\n",
              "         219: 1,\n",
              "         223: 1,\n",
              "         224: 1,\n",
              "         226: 2,\n",
              "         230: 1,\n",
              "         234: 1,\n",
              "         239: 1,\n",
              "         244: 1,\n",
              "         245: 1,\n",
              "         247: 1,\n",
              "         255: 1,\n",
              "         260: 1,\n",
              "         266: 1,\n",
              "         269: 1,\n",
              "         273: 1,\n",
              "         275: 1,\n",
              "         276: 1,\n",
              "         285: 1,\n",
              "         287: 1,\n",
              "         289: 1,\n",
              "         296: 1,\n",
              "         298: 1,\n",
              "         301: 1,\n",
              "         304: 1,\n",
              "         305: 2,\n",
              "         314: 1,\n",
              "         322: 1,\n",
              "         324: 1,\n",
              "         329: 2,\n",
              "         334: 1,\n",
              "         337: 1,\n",
              "         342: 1,\n",
              "         348: 1,\n",
              "         355: 1,\n",
              "         358: 2,\n",
              "         362: 1,\n",
              "         363: 1,\n",
              "         368: 1,\n",
              "         369: 1,\n",
              "         376: 1,\n",
              "         379: 1,\n",
              "         380: 1,\n",
              "         386: 1,\n",
              "         399: 1,\n",
              "         421: 1,\n",
              "         428: 1,\n",
              "         442: 1,\n",
              "         446: 1,\n",
              "         447: 1,\n",
              "         452: 1,\n",
              "         456: 1,\n",
              "         458: 1,\n",
              "         462: 1,\n",
              "         481: 1,\n",
              "         482: 1,\n",
              "         497: 1,\n",
              "         507: 1,\n",
              "         528: 2,\n",
              "         532: 2,\n",
              "         546: 1,\n",
              "         547: 1,\n",
              "         566: 1,\n",
              "         584: 1,\n",
              "         585: 1,\n",
              "         603: 1,\n",
              "         620: 1,\n",
              "         644: 1,\n",
              "         657: 1,\n",
              "         667: 1,\n",
              "         668: 1,\n",
              "         720: 2,\n",
              "         723: 1,\n",
              "         789: 1,\n",
              "         801: 1,\n",
              "         817: 1,\n",
              "         852: 1,\n",
              "         866: 1,\n",
              "         881: 1,\n",
              "         906: 1,\n",
              "         922: 1,\n",
              "         939: 1,\n",
              "         984: 1,\n",
              "         1007: 1,\n",
              "         1058: 1,\n",
              "         1067: 1,\n",
              "         1092: 1,\n",
              "         1152: 1,\n",
              "         1155: 1,\n",
              "         1181: 1,\n",
              "         1197: 1,\n",
              "         1202: 1,\n",
              "         1285: 1,\n",
              "         1306: 1,\n",
              "         1322: 1,\n",
              "         1336: 2,\n",
              "         1400: 1,\n",
              "         1446: 1,\n",
              "         1519: 1,\n",
              "         1549: 1,\n",
              "         1577: 1,\n",
              "         1599: 1,\n",
              "         1618: 1,\n",
              "         1622: 1,\n",
              "         1770: 1,\n",
              "         1775: 1,\n",
              "         1840: 1,\n",
              "         1872: 1,\n",
              "         1882: 1,\n",
              "         1888: 1,\n",
              "         1903: 1,\n",
              "         1913: 1,\n",
              "         2007: 1,\n",
              "         2121: 1,\n",
              "         2336: 1,\n",
              "         2501: 1,\n",
              "         3966: 1,\n",
              "         4385: 1,\n",
              "         4480: 1,\n",
              "         4857: 1,\n",
              "         4977: 1,\n",
              "         5619: 1,\n",
              "         6009: 1,\n",
              "         6322: 1,\n",
              "         6601: 1,\n",
              "         7851: 1,\n",
              "         11940: 1,\n",
              "         34655: 1})"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(row):\n",
        "  if row['retweets'] >15:\n",
        "    cat = 7\n",
        "  elif row['retweets'] >8:\n",
        "    cat= 6\n",
        "  elif row['retweets'] >5:\n",
        "    cat = 5\n",
        "  elif row['retweets'] >=4:\n",
        "    cat = 4\n",
        "  else:\n",
        "    cat = row['retweets']\n",
        "  return cat\n",
        "df2['cat'] = df2.apply(convert, axis=1)"
      ],
      "metadata": {
        "id": "WKzjibNdRpwL"
      },
      "id": "WKzjibNdRpwL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(df2.cat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkRCsszoOil-",
        "outputId": "1b821318-a83e-4768-f33b-dc06d326b233"
      },
      "id": "KkRCsszoOil-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 4000,\n",
              "         1: 4000,\n",
              "         2: 4240,\n",
              "         3: 3280,\n",
              "         4: 4530,\n",
              "         5: 3664,\n",
              "         6: 3447,\n",
              "         7: 3877})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDuZydBHUeLc",
        "outputId": "3d2162c0-ca99-4b57-bf40-ed5085602274"
      },
      "id": "oDuZydBHUeLc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31038, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df2.iloc[:30720]\n",
        "df3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXF58U2RFhC6",
        "outputId": "1e635731-9784-4a04-b3bb-c8dd5489ed0d"
      },
      "id": "OXF58U2RFhC6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30720, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_encoded = list()\n",
        "for item in df3['cat']:\n",
        "\tvalues = [0 for _ in range(8)]\n",
        "\tvalues[item] = 1\n",
        "\tonehot_encoded.append(values)"
      ],
      "metadata": {
        "id": "fMIMkQN1I_Oh"
      },
      "id": "fMIMkQN1I_Oh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_encoded[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kADgVRkLJES",
        "outputId": "61bd2d8a-743a-4cba-8239-7e444ff48737"
      },
      "id": "2kADgVRkLJES",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(onehot_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpZbgsdUJTNk",
        "outputId": "696c7cc8-f39b-4c27-f871-cfa65bc2964a"
      },
      "id": "xpZbgsdUJTNk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30720"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df3.iloc[:,:-2], onehot_encoded, test_size = 0.1, random_state=42)\n",
        "print(len(X_train), len(X_test))\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 2816, random_state=42)\n",
        "print(len(X_train), len(X_test), len(X_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm8Yp2ZqNJyI",
        "outputId": "eefa46ad-9d7d-4eec-8ab9-f00844be076b"
      },
      "id": "Wm8Yp2ZqNJyI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27648 3072\n",
            "24832 3072 2816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tweet = X_train.tweet\n",
        "X_val_tweet = X_val.tweet\n",
        "X_test_tweet = X_test.tweet\n",
        "\n",
        "X_train_meta = X_train.iloc[:,:-1]\n",
        "X_val_meta = X_val.iloc[:,:-1]\n",
        "X_test_meta = X_test.iloc[:,:-1]"
      ],
      "metadata": {
        "id": "ZzutBlDAmyXP"
      },
      "id": "ZzutBlDAmyXP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building vocabulary for training data\n",
        "def word_count(data):\n",
        "  words_counter = Counter()\n",
        "  for line in data:\n",
        "    words =  str(line).split()\n",
        "    for w in words:\n",
        "      words_counter.update([w])\n",
        "  \n",
        "  words_counter_clean = {k:v for k,v in words_counter.items() if v > 1} # Removing the words that only appear once\n",
        "  sorted_words = sorted(words_counter_clean, key = words_counter_clean.get, reverse = True) # Sorting the words frequency in desc order\n",
        "  sorted_words = ['UNK','PAD', '<s>', '</s>' ] + sorted_words \n",
        "\n",
        "  return words_counter, words_counter_clean, sorted_words\n",
        "  \n",
        "words_counter, words_counter_clean, sorted_words = word_count(X_train_tweet)"
      ],
      "metadata": {
        "id": "uH6X4dcoOPLI"
      },
      "id": "uH6X4dcoOPLI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Not using slicing window padding\n",
        "def padding(data, seq_len):\n",
        "  sequences = []\n",
        "  for line in data:\n",
        "    line = f\"{'<s>'} {line} {'</s>'}\"\n",
        "    n_token = len(line.split())\n",
        "    \n",
        "    if n_token >= seq_len:\n",
        "      seq = line.split()[:seq_len] \n",
        "      sequences.append(\" \".join(seq))\n",
        "\n",
        "    else:\n",
        "      seq = line.split()\n",
        "      for i in range(seq_len - n_token):\n",
        "          seq.append('PAD')\n",
        "      sequences.append(\" \".join(seq))\n",
        "  return sequences\n",
        "\n",
        "X_train_pad = padding(X_train_tweet, 20)\n",
        "X_val_pad = padding(X_val_tweet, 20)\n",
        "X_test_pad = padding(X_test_tweet, 20)"
      ],
      "metadata": {
        "id": "QbqatJDhN9hj"
      },
      "id": "QbqatJDhN9hj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace the words that only appear once with UNKNOWN\n",
        "def generate_sentence(data):\n",
        "  sequences = []\n",
        "  for line in data:\n",
        "    temp = []\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "      if word in sorted_words:\n",
        "        temp.append(word)\n",
        "      else:\n",
        "        temp.append('UNK')\n",
        "    sequences.append(\" \".join(temp))\n",
        "  return sequences\n",
        "\n",
        "X_train_final = generate_sentence(X_train_pad)\n",
        "X_val_final = generate_sentence(X_val_pad)\n",
        "X_test_final = generate_sentence(X_test_pad)"
      ],
      "metadata": {
        "id": "8P30CPRaOfyW"
      },
      "id": "8P30CPRaOfyW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o54nmNt2w4sd",
      "metadata": {
        "id": "o54nmNt2w4sd"
      },
      "outputs": [],
      "source": [
        "# Using tweets training data vocabulary\n",
        "\n",
        "# Dictionaries to store the word to index mappings and vice versa\n",
        "word2idx = {o:i for i,o in enumerate(sorted_words)}\n",
        "idx2word = {i:o for i,o in enumerate(sorted_words)}\n",
        "\n",
        "\n",
        "# convert text sequences to integer sequences\n",
        "X_train_int = np.zeros((len(X_train_final), 20), dtype = int)\n",
        "for i, data in enumerate(X_train_final):\n",
        "  X_train_int[i] = [word2idx[w] for w in data.split()]\n",
        "\n",
        "X_val_int = np.zeros((len(X_val_final), 20), dtype = int)\n",
        "for i, data in enumerate(X_val_final):\n",
        "  X_val_int[i] = [word2idx[w] for w in data.split()]\n",
        "\n",
        "X_test_int = np.zeros((len(X_test_final), 20), dtype = int)\n",
        "for i, data in enumerate(X_test_final):\n",
        "  X_test_int[i] = [word2idx[w] for w in data.split()]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert lists to numpy arrays\n",
        "X_train_int = np.array(X_train_int)\n",
        "y_train_int = np.array(y_train)\n",
        "\n",
        "X_val_int = np.array(X_val_int)\n",
        "y_val_int = np.array(y_val)\n",
        "\n",
        "X_test_int = np.array(X_test_int)\n",
        "y_test_int = np.array(y_test)"
      ],
      "metadata": {
        "id": "naTOqvd7Vg6m"
      },
      "id": "naTOqvd7Vg6m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# create Tensor datasets\n",
        "#train_data = TensorDataset(torch.from_numpy(X_train_int),  torch.from_numpy(y_train_int))\n",
        "#val_data = TensorDataset(torch.from_numpy(X_val_int),torch.from_numpy(y_val_int))\n",
        "#test_data = TensorDataset(torch.from_numpy(X_test_int), torch.from_numpy(y_test_int))\n",
        "\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(X_train_int), torch.from_numpy(X_train_meta.to_numpy()), torch.from_numpy(y_train_int))\n",
        "val_data = TensorDataset(torch.from_numpy(X_val_int),torch.from_numpy(X_val_meta.to_numpy()), torch.from_numpy(y_val_int))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test_int),torch.from_numpy(X_test_meta.to_numpy()), torch.from_numpy(y_test_int))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "V526jI1Glo7o"
      },
      "id": "V526jI1Glo7o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7a3ac567",
      "metadata": {
        "id": "7a3ac567"
      },
      "source": [
        "# Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ii7TYo3rL1-",
      "metadata": {
        "id": "6ii7TYo3rL1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f344dd2-bacd-4549-98aa-3a422b59e50d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# Using glove weights\n",
        "words_glove = []\n",
        "idx_glove = 0\n",
        "word2idx_glove = {}\n",
        "vectors_glove = []\n",
        "\n",
        "with open(f'{path}/glove.twitter.27B.100d.txt', 'rb') as f:\n",
        "  for l in f:\n",
        "    line = l.decode().split()\n",
        "    word = line[0]\n",
        "    words_glove.append(word)\n",
        "    word2idx_glove[word] = idx_glove\n",
        "    idx_glove += 1\n",
        "    vect = np.array(line[1:]).astype(np.float)\n",
        "    vectors_glove.append(vect)\n",
        "    \n",
        "\n",
        "glove = {w: vectors_glove[word2idx_glove[w]] for w in words_glove}\n",
        "matrix_len = len(sorted_words)\n",
        "weights_matrix = np.zeros((matrix_len, 100))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(sorted_words):\n",
        "  try: \n",
        "    weights_matrix[i] = glove[word] # if alr in the vocab, load its pre-trained word vector.\n",
        "    words_found += 1\n",
        "  except KeyError:\n",
        "    weights_matrix[i] = np.random.normal(scale=0.6, size=(100, ))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e5b8d40",
      "metadata": {
        "id": "5e5b8d40"
      },
      "source": [
        "# Neural Net\n",
        "\n",
        "### Retweet Network: Takes in a tweet as input, can use embedded version, and can any combination of bidirectional, LSTM, GRU, concatenates it with metadata vector, and uses a feedforward neural net with 1 hidden layer to perform a regression prediction on the retweet count. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96c224d1",
      "metadata": {
        "id": "96c224d1"
      },
      "source": [
        "#### Parameter custom_embeddings is either a tuple: (weight_matrix , none_trainable), or None.\n",
        "#### none_trainable is either True or False or Nothing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "  num_embeddings, embedding_dim = weights_matrix.shape\n",
        "  emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "  emb_layer.load_state_dict({'weight': torch.from_numpy(weights_matrix)})\n",
        "  if non_trainable:\n",
        "      emb_layer.weight.requires_grad = False\n",
        "  return emb_layer, num_embeddings, embedding_dim\n",
        "\n",
        "class RetweetNet(nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_state_sizes, meta_data_len, output_size, embedding_dim, hidden_dim, \n",
        "                 n_layers, drop_prob=0.5, custom_embeddings = None, bidirectional = False, GRU = False):\n",
        "    super().__init__()\n",
        "    self.GRU_val = GRU\n",
        "    self.bidirectional = bidirectional\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "        \n",
        "    if custom_embeddings is None: \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    else: \n",
        "        assert len(custom_embeddings) == 2 and isinstance(custom_embeddings, tuple), \"custom embeddings must be of form: (weight_matrix, non_trainable)\"\n",
        "        weights_matrix, non_trainable = custom_embeddings\n",
        "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, non_trainable)\n",
        "        \n",
        "    if GRU == False: \n",
        "        self.Gate = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True, bidirectional = bidirectional)\n",
        "    else: \n",
        "        self.Gate = nn.GRU(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True, bidirectional = bidirectional)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.fc1 = nn.Linear(hidden_dim, hidden_state_sizes[0])\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    #hidden_state_sizes[0] is the size of the output of lstm \n",
        "    self.fc2 = nn.Linear(hidden_state_sizes[0] + meta_data_len, hidden_state_sizes[1])\n",
        "        \n",
        "    #hidden_state_sizes[1] is the size of the first and only hidden layer\n",
        "    self.fc3 = nn.Linear(hidden_state_sizes[1], 8)\n",
        "\n",
        "        \n",
        "  def forward(self, x, meta_data, hidden):\n",
        "    batch_size = x.size(0)\n",
        "    x = x.long()\n",
        "    embeds = self.embedding(x)\n",
        "    gru_out, hidden = self.Gate(embeds, hidden)\n",
        "    gru_out = gru_out.contiguous().view(-1, self.hidden_dim)\n",
        "    \n",
        "    out = self.dropout(gru_out)\n",
        "    out = self.fc1(out)\n",
        "\n",
        "    out = out.view(batch_size, -1, self.hidden_dim)\n",
        "    out = out[:,-1, :] \n",
        "\n",
        "    # combine hidden state and meta_data\n",
        "    ################# ################# #################\n",
        "    #out = torch.cat((out, meta_data), dim = 1) #meta_data is of shape (batch_size, -1)\n",
        "        \n",
        "    out = self.fc2(out)\n",
        "        \n",
        "    # applying dropout before relu since relu already sets some neurons to 0\n",
        "    out = self.dropout(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc3(out)\n",
        "    out = self.softmax(out)\n",
        "        \n",
        "    return out, hidden\n",
        "    \n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    n = 1\n",
        "    if self.bidirectional == True: \n",
        "      n = 2\n",
        "    if self.GRU_val == False:\n",
        "      return (weight.new(self.n_layers * n, batch_size, self.hidden_dim).zero_().to('cuda'),\n",
        "              weight.new(self.n_layers * n, batch_size, self.hidden_dim).zero_().to('cuda'))\n",
        "    else:\n",
        "      return  weight.new(self.n_layers * n, batch_size, self.hidden_dim).zero_().to('cuda')\n",
        "\n",
        "\n",
        "def train_retweet_predictor(model, epochs = 100, print_every = 1000, clip = 5, valid_loss_min = np.Inf, lr=0.005, batch_size = 400, device = 'cuda', GRU = False, weight_decay = 1e-5): \n",
        "  counter = 0\n",
        "  print_every = 150\n",
        "  training_stats = []\n",
        "  model.train()\n",
        "    \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "  # weight decay is the l2 regularization penalty \n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "  training_stats = []\n",
        "  for i in range(epochs):\n",
        "    total_train_loss = []\n",
        "    total_val_loss = []\n",
        "  \n",
        "\n",
        "    h = model.init_hidden(batch_size)\n",
        "    for tweets, meta_data, labels in train_loader:\n",
        "      counter += 1\n",
        "      if GRU == False: \n",
        "        h = tuple([each.data for each in h])\n",
        "      else:\n",
        "        h = h.data\n",
        "      tweets, meta_data, labels = tweets.to(device), meta_data.to(device), labels.to(device)\n",
        "      model.zero_grad()\n",
        "      output, h = model(tweets, meta_data, h)\n",
        "      loss = criterion(output.squeeze(), labels.float())\n",
        "      loss.backward()\n",
        "      total_train_loss.append(loss.item())\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      optimizer.step()\n",
        "\n",
        "      if counter % print_every == 0:\n",
        "        val_h = model.init_hidden(batch_size)\n",
        "        model.eval()\n",
        "        for tweets, meta_data, labels in val_loader:\n",
        "          if GRU == False: \n",
        "            val_h = tuple([each.data for each in val_h])\n",
        "          else:\n",
        "            val_h = val_h.data\n",
        "\n",
        "          tweets, meta_data, labels = tweets.to(device), meta_data.to(device), labels.to(device)\n",
        "          \n",
        "          output, val_h = model(tweets, meta_data, val_h)\n",
        "          val_loss = criterion(output.squeeze(), labels.float())\n",
        "          total_val_loss.append(val_loss.item())\n",
        "        \n",
        "        model.train()\n",
        "        print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "            \"Step: {}...\".format(counter),\n",
        "            \"Loss: {:.6f}...\".format(loss.item()),\n",
        "            \"Val Loss: {:.6f}\".format(np.mean(total_val_loss)))\n",
        "    \n",
        "      \n",
        "\n",
        "    #print('----------------------------------------------------------')\n",
        "    #avg_train_loss = np.mean(total_train_loss)  \n",
        "    #avg_val_loss = np.mean(total_val_loss)  \n",
        "    #median_train_loss = np.median(total_train_loss)  \n",
        "    #print(\"Average train loss: {:.6f}...\".format(avg_train_loss),  \" Median train loss:  {:.6f}...\".format(median_train_loss))\n",
        "    #training_stats.append({'epoch': i + 1, 'Training Loss': avg_train_loss})\n",
        "\n",
        "      \n",
        "\n"
      ],
      "metadata": {
        "id": "xGLQtrqBeoOr"
      },
      "id": "xGLQtrqBeoOr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(sorted_words)\n",
        "output_size = len(X_train_int)\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = RetweetNet(vocab_size = vocab_size, hidden_state_sizes = [256,128], meta_data_len = 0, output_size = output_size, embedding_dim = embedding_dim, hidden_dim  = hidden_dim, \n",
        "                 n_layers =n_layers, GRU = True, bidirectional = False)\n",
        "net.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqetYzck9STm",
        "outputId": "5d5be078-54ef-4e7b-d57f-f5694fdb2585"
      },
      "id": "DqetYzck9STm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RetweetNet(\n",
              "  (embedding): Embedding(11127, 100)\n",
              "  (Gate): GRU(100, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (softmax): Softmax(dim=1)\n",
              "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_retweet_predictor(net, epochs = 50, batch_size = 256, device = 'cuda', lr = 1e-06,GRU = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HUVj0V9v0HW",
        "outputId": "a84ab957-75ad-4c0d-f804-830ed3f7ef27"
      },
      "id": "1HUVj0V9v0HW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/50... Step: 150... Loss: 2.180259... Val Loss: 2.159662\n",
            "Epoch: 4/50... Step: 300... Loss: 2.149009... Val Loss: 2.159662\n",
            "Epoch: 5/50... Step: 450... Loss: 2.176353... Val Loss: 2.159662\n",
            "Epoch: 7/50... Step: 600... Loss: 2.090415... Val Loss: 2.159662\n",
            "Epoch: 8/50... Step: 750... Loss: 2.156821... Val Loss: 2.159662\n",
            "Epoch: 10/50... Step: 900... Loss: 2.117759... Val Loss: 2.159662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def error_retweet_predictor(model, batch_size = 359, device = 'cuda', GRU = False): \n",
        "  test_losses = []\n",
        "  num_correct = 0\n",
        "  model.cuda()\n",
        "\n",
        "  h = model.init_hidden(batch_size)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "\n",
        "  model.eval()\n",
        "  for tweets, meta_data, labels in test_loader:\n",
        "    if GRU == True: \n",
        "      h = h.data\n",
        "    else: \n",
        "      h = tuple([each.data for each in h])\n",
        "    tweets, meta_data, labels = tweets.to(device), meta_data.to(device), labels.to(device)\n",
        "    output, h = model(tweets, meta_data, h)\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    #pred = torch.round(output.squeeze())\n",
        "    _, test_predicted = torch.max(output.data,1)\n",
        "    _, labels = torch.max(labels,1)\n",
        "    #print(test_predicted)\n",
        "    num_correct += torch.eq(labels, test_predicted).sum()\n",
        "    \n",
        "    #correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "\n",
        "    #correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "\n",
        "    #num_correct += np.sum(correct)   \n",
        "   \n",
        "  test_acc = num_correct/len(test_loader.dataset)\n",
        "  print(num_correct, len(test_loader.dataset))\n",
        "  print(\"Average test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "  #print(\"Median test loss: {:.3f}\".format(np.median(test_losses)))\n",
        "  print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "id": "jy-20t06tV6m"
      },
      "id": "jy-20t06tV6m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_retweet_predictor(net, batch_size = 256, device = 'cuda', GRU = True) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_QOdfST0z07",
        "outputId": "04e6e1ff-ac35-4fde-dec0-47b32d2e869c"
      },
      "id": "r_QOdfST0z07",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(347, device='cuda:0') 3072\n",
            "Average test loss: 2.161\n",
            "Test accuracy: 0.113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RetweetNet(nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_state_sizes, meta_data_len, output_size, embedding_dim, hidden_dim, \n",
        "                 n_layers, drop_prob=0.5, custom_embeddings = None, bidirectional = False, GRU = False):\n",
        "    super().__init__()\n",
        "    self.GRU_val = GRU\n",
        "    self.bidirectional = bidirectional\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "        \n",
        "    if custom_embeddings is None: \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    else: \n",
        "        assert len(custom_embeddings) == 2 and isinstance(custom_embeddings, tuple), \"custom embeddings must be of form: (weight_matrix, non_trainable)\"\n",
        "        weights_matrix, non_trainable = custom_embeddings\n",
        "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, non_trainable)\n",
        "        \n",
        "    if GRU == False: \n",
        "        self.Gate = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True, bidirectional = bidirectional)\n",
        "    else: \n",
        "        self.Gate = nn.GRU(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True, bidirectional = bidirectional)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.fc1 = nn.Linear(hidden_dim, hidden_state_sizes[0])\n",
        "    self.relu = nn.ReLU()\n",
        "        \n",
        "    #hidden_state_sizes[0] is the size of the output of lstm \n",
        "    self.fc2 = nn.Linear(hidden_state_sizes[0] + meta_data_len, hidden_state_sizes[1])\n",
        "        \n",
        "    #hidden_state_sizes[1] is the size of the first and only hidden layer\n",
        "    self.fc3 = nn.Linear(hidden_state_sizes[1], 1)\n",
        "\n",
        "        \n",
        "  def forward(self, x, meta_data, hidden):\n",
        "    batch_size = x.size(0)\n",
        "    x = x.long()\n",
        "    embeds = self.embedding(x)\n",
        "    gru_out, hidden = self.Gate(embeds, hidden)\n",
        "    gru_out = gru_out.contiguous().view(-1, self.hidden_dim)\n",
        "    \n",
        "    out = self.dropout(gru_out)\n",
        "    out = self.fc1(out)\n",
        "\n",
        "    out = out.view(batch_size, -1, self.hidden_dim)\n",
        "    out = out[:,-1, :] \n",
        "\n",
        "    # combine hidden state and meta_data\n",
        "    ################# ################# #################\n",
        "    out = torch.cat((out, meta_data), dim = 1) #meta_data is of shape (batch_size, -1)\n",
        "        \n",
        "    out = self.fc2(out)\n",
        "        \n",
        "    # applying dropout before relu since relu already sets some neurons to 0\n",
        "    out = self.dropout(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc3(out)\n",
        "        \n",
        "    return out, hidden\n",
        "    \n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    n = 1\n",
        "    if self.bidirectional == True: \n",
        "      n = 2\n",
        "    if self.GRU_val == False:\n",
        "      return (weight.new(self.n_layers * n, batch_size, self.hidden_dim).zero_().to('cuda'),\n",
        "              weight.new(self.n_layers * n, batch_size, self.hidden_dim).zero_().to('cuda'))\n",
        "    else:\n",
        "      return  weight.new(self.n_layers * n, batch_size, self.hidden_dim).zero_().to('cuda')\n",
        "\n",
        "\n",
        "def train_retweet_predictor(model, epochs = 100, print_every = 1000, clip = 5, valid_loss_min = np.Inf, lr=0.005, batch_size = 400, device = 'cuda', GRU = False, weight_decay = 1e-5): \n",
        "  counter = 0\n",
        "  print_every = 150\n",
        "  training_stats = []\n",
        "  model.train()\n",
        "    \n",
        "  criterion = nn.MSELoss()\n",
        "    \n",
        "  # weight decay is the l2 regularization penalty \n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "  training_stats = []\n",
        "  for i in range(epochs):\n",
        "    total_train_loss = []\n",
        "    total_val_loss = []\n",
        "  \n",
        "\n",
        "    h = model.init_hidden(batch_size)\n",
        "    for tweets, meta_data, labels in train_loader:\n",
        "      counter += 1\n",
        "      if GRU == False: \n",
        "        h = tuple([each.data for each in h])\n",
        "      else:\n",
        "        h = h.data\n",
        "      tweets, meta_data, labels = tweets.to(device), meta_data.to(device), labels.to(device)\n",
        "      model.zero_grad()\n",
        "      output, h = model(tweets, meta_data, h)\n",
        "      loss = criterion(output.squeeze(), labels.float())\n",
        "      loss.backward()\n",
        "      total_train_loss.append(loss.item())\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      optimizer.step()\n",
        "\n",
        "      if counter % print_every == 0:\n",
        "        val_h = model.init_hidden(batch_size)\n",
        "        model.eval()\n",
        "        for tweets, meta_data, labels in val_loader:\n",
        "          if GRU == False: \n",
        "            val_h = tuple([each.data for each in val_h])\n",
        "          else:\n",
        "            val_h = val_h.data\n",
        "\n",
        "          tweets, meta_data, labels = tweets.to(device), meta_data.to(device), labels.to(device)\n",
        "          \n",
        "          output, val_h = model(tweets, meta_data, val_h)\n",
        "          val_loss = criterion(output.squeeze(), labels.float())\n",
        "          total_val_loss.append(val_loss.item())\n",
        "        \n",
        "        model.train()\n",
        "        print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "            \"Step: {}...\".format(counter),\n",
        "            \"Loss: {:.6f}...\".format(loss.item()),\n",
        "            \"Val Loss: {:.6f}\".format(np.mean(total_val_loss)))\n",
        "     \n",
        "\n"
      ],
      "metadata": {
        "id": "buCLM2hT047v"
      },
      "id": "buCLM2hT047v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(sorted_words)\n",
        "output_size = len(X_train_int)\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = RetweetNet(vocab_size = vocab_size, hidden_state_sizes = [256,128], meta_data_len = 4, output_size = output_size, embedding_dim = embedding_dim, hidden_dim  = hidden_dim, \n",
        "                 n_layers =n_layers, GRU = True, bidirectional = False)\n",
        "net.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6nF1J3S3CCL",
        "outputId": "321a3b70-d0a9-47c9-cbd3-d3aa25f45084"
      },
      "id": "C6nF1J3S3CCL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RetweetNet(\n",
              "  (embedding): Embedding(11127, 100)\n",
              "  (Gate): GRU(100, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=260, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_retweet_predictor(net, epochs = 20, batch_size = 256, device = 'cuda', lr = 1e-06,GRU = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6-iCL-f3KEr",
        "outputId": "cb3b3b99-e560-4522-b537-f33a26eca315"
      },
      "id": "r6-iCL-f3KEr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/20... Step: 150... Loss: 13945278.000000... Val Loss: 547035.002841\n",
            "Epoch: 4/20... Step: 300... Loss: 12154663.000000... Val Loss: 297339.819602\n",
            "Epoch: 5/20... Step: 450... Loss: 7641081.500000... Val Loss: 177986.725852\n",
            "Epoch: 7/20... Step: 600... Loss: 10039762.000000... Val Loss: 100861.974432\n",
            "Epoch: 8/20... Step: 750... Loss: 6030792.000000... Val Loss: 66152.366655\n",
            "Epoch: 10/20... Step: 900... Loss: 6535027.000000... Val Loss: 51764.672230\n",
            "Epoch: 11/20... Step: 1050... Loss: 8651229.000000... Val Loss: 44701.617365\n",
            "Epoch: 13/20... Step: 1200... Loss: 13521440.000000... Val Loss: 38858.325728\n",
            "Epoch: 14/20... Step: 1350... Loss: 8789524.000000... Val Loss: 37455.836825\n",
            "Epoch: 16/20... Step: 1500... Loss: 8275924.500000... Val Loss: 34446.629528\n",
            "Epoch: 18/20... Step: 1650... Loss: 10241644.000000... Val Loss: 31953.952770\n",
            "Epoch: 19/20... Step: 1800... Loss: 14811671.000000... Val Loss: 30727.829146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_retweet_predictor(net, batch_size = 256, device = 'cuda', GRU = True) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzCNiU4I3o5H",
        "outputId": "2a23dc54-390e-4e2d-d2f7-c11a7cba4b48"
      },
      "id": "pzCNiU4I3o5H",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33 3072\n",
            "Average test loss: 34057.910\n",
            "Median test loss: 26435.905\n",
            "Test accuracy: 0.011\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of new model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}