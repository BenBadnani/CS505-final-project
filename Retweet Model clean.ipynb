{"cells":[{"cell_type":"code","execution_count":null,"id":"ghIfS47AVBd1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghIfS47AVBd1","outputId":"d131d0ac-8031-4256-e372-323779772389","executionInfo":{"status":"ok","timestamp":1651431572341,"user_tz":240,"elapsed":6223,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bcolz in /usr/local/lib/python3.7/dist-packages (1.2.1)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from bcolz) (1.21.6)\n"]}],"source":["!pip install bcolz"]},{"cell_type":"code","execution_count":null,"id":"96da3e8a","metadata":{"id":"96da3e8a"},"outputs":[],"source":["import numpy as np \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from google.colab import files\n","import bcolz\n","import pickle\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","import csv\n","import json\n","import pandas as pd\n","from collections import Counter\n","import spacy\n","import re\n","nlp = spacy.load('en_core_web_sm')\n","#stopwords = nlp.Defaults.stop_words"]},{"cell_type":"code","execution_count":null,"id":"adKAoZQWWzm7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adKAoZQWWzm7","outputId":"62f2bd35-db86-4ab4-88d7-14729be22e05","executionInfo":{"status":"ok","timestamp":1651431577501,"user_tz":240,"elapsed":695,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"YRMqlKGAny0z","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YRMqlKGAny0z","outputId":"641e5604-44c8-46b3-c6a7-d936ea40f8c1","executionInfo":{"status":"ok","timestamp":1651432451021,"user_tz":240,"elapsed":236,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(96562, 9)\n"]}],"source":["path = '/content/drive/MyDrive/505/project/'\n","\n","data = pd.read_csv(f'{path}/data.csv')\n","print(data.shape)"]},{"cell_type":"code","source":["tweets_count = []\n","for item in data['tweet']:\n","  n = len(str(item).split())\n","  tweets_count.append(n)\n","\n","data['tweet_len'] = tweets_count\n","len(tweets_count)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"orG2qQox86O-","executionInfo":{"status":"ok","timestamp":1651432452022,"user_tz":240,"elapsed":236,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"4596d70b-2d7c-400c-8a8c-d76b13b67a60"},"id":"orG2qQox86O-","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["96562"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["from collections import Counter\n","print('video:' , Counter(data.video))\n","print('photo:' , Counter(data.photo))\n","print('animated_gif:', Counter(data.animated_gif))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zMjvJK1kBTWN","executionInfo":{"status":"ok","timestamp":1651432452737,"user_tz":240,"elapsed":99,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"4af618c3-4e41-4cb7-e026-b3672df7617e"},"id":"zMjvJK1kBTWN","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["video: Counter({0: 96562})\n","photo: Counter({0: 88522, 1: 8040})\n","animated_gif: Counter({0: 96562})\n"]}]},{"cell_type":"code","source":["data = data[data['tweet_len'] > 1]\n","needed = ['user_friends_count', 'user_followers_count', 'favorite_count',\n","       'user_statuses_count', 'tweet','retweets']\n","data = data[needed]\n","df = data.iloc[:96000]\n","print(df.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OVOX0u-4vq2j","executionInfo":{"status":"ok","timestamp":1651432458298,"user_tz":240,"elapsed":101,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"674c562e-ab58-4598-9c9c-a511edb0995a"},"id":"OVOX0u-4vq2j","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(96000, 6)\n"]}]},{"cell_type":"code","source":["df.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"ov7SB8zQCkez","executionInfo":{"status":"ok","timestamp":1651432463005,"user_tz":240,"elapsed":102,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"94755acc-4834-450e-aff7-86fa1a7dd950"},"id":"ov7SB8zQCkez","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   user_friends_count  user_followers_count  favorite_count  \\\n","0               13723                120597               0   \n","1               13723                120597               0   \n","\n","   user_statuses_count                                              tweet  \\\n","0               153810  <user> hi no you can not withdraw funds but yo...   \n","1               153810  <user> hi can you please share more informatio...   \n","\n","   retweets  \n","0         0  \n","1         0  "],"text/html":["\n","  <div id=\"df-768ceac3-1679-41b3-b6c6-6f637587f287\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_friends_count</th>\n","      <th>user_followers_count</th>\n","      <th>favorite_count</th>\n","      <th>user_statuses_count</th>\n","      <th>tweet</th>\n","      <th>retweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13723</td>\n","      <td>120597</td>\n","      <td>0</td>\n","      <td>153810</td>\n","      <td>&lt;user&gt; hi no you can not withdraw funds but yo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13723</td>\n","      <td>120597</td>\n","      <td>0</td>\n","      <td>153810</td>\n","      <td>&lt;user&gt; hi can you please share more informatio...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-768ceac3-1679-41b3-b6c6-6f637587f287')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-768ceac3-1679-41b3-b6c6-6f637587f287 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-768ceac3-1679-41b3-b6c6-6f637587f287');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["Counter(df.retweets).most_common(10)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F4GXZzYgDHnd","executionInfo":{"status":"ok","timestamp":1651432788553,"user_tz":240,"elapsed":130,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"b9794a92-5a87-4894-ee70-b31989041676"},"id":"F4GXZzYgDHnd","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 64830),\n"," (1, 8133),\n"," (2, 4240),\n"," (3, 3280),\n"," (4, 2523),\n"," (5, 2007),\n"," (6, 1506),\n"," (7, 1226),\n"," (8, 932),\n"," (9, 801)]"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["class_0 = df[df['retweets'] == 0]\n","class_not0 = df[df['retweets'] != 0]"],"metadata":{"id":"TvUnl5sIE6at"},"id":"TvUnl5sIE6at","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_0_under = class_0.sample(8133)\n","print(class_0_under.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hC_G9cc4FOY-","executionInfo":{"status":"ok","timestamp":1651433567511,"user_tz":240,"elapsed":96,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"ae483482-4d03-417e-df31-ed09047ab12e"},"id":"hC_G9cc4FOY-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(8133, 6)\n"]}]},{"cell_type":"code","source":["df2 = pd.concat([class_0_under, class_not0], axis=0)\n","df2.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AeFdKyDGFXWF","executionInfo":{"status":"ok","timestamp":1651433568194,"user_tz":240,"elapsed":140,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"ccdcf87b-e5b9-4fba-8a2d-e79924da7d0f"},"id":"AeFdKyDGFXWF","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(39303, 6)"]},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":["df3 = df2.iloc[:32000]"],"metadata":{"id":"OXF58U2RFhC6"},"id":"OXF58U2RFhC6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train test split\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(df3.iloc[:,:-1], df3['retweets'], test_size = 0.2, random_state=42)\n","print(len(X_train), len(X_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wm8Yp2ZqNJyI","executionInfo":{"status":"ok","timestamp":1651433574757,"user_tz":240,"elapsed":107,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"d80bd1a4-5d3d-4ca1-9e1f-5fa94ff6993c"},"id":"Wm8Yp2ZqNJyI","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["25600 6400\n"]}]},{"cell_type":"code","source":["X_train_tweet = X_train.tweet\n","X_test_tweet = X_test.tweet\n","\n","X_train_meta = X_train.iloc[:,:-1]\n","X_test_meta = X_test.iloc[:,:-1]"],"metadata":{"id":"ZzutBlDAmyXP"},"id":"ZzutBlDAmyXP","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Building vocabulary for training data\n","def word_count(data):\n","  words_counter = Counter()\n","  for line in data:\n","    words =  str(line).split()\n","    for w in words:\n","      words_counter.update([w])\n","  \n","  words_counter_clean = {k:v for k,v in words_counter.items() if v > 1} # Removing the words that only appear once\n","  sorted_words = sorted(words_counter_clean, key = words_counter_clean.get, reverse = True) # Sorting the words frequency in desc order\n","  sorted_words = ['UNK','PAD', '<s>', '</s>' ] + sorted_words \n","\n","  return words_counter, words_counter_clean, sorted_words\n","  \n","words_counter, words_counter_clean, sorted_words = word_count(X_train_tweet)"],"metadata":{"id":"uH6X4dcoOPLI"},"id":"uH6X4dcoOPLI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Not using slicing window padding\n","def padding(data, seq_len):\n","  sequences = []\n","  for line in data:\n","    line = f\"{'<s>'} {line} {'</s>'}\"\n","    n_token = len(line.split())\n","    \n","    if n_token >= seq_len:\n","      seq = line.split()[:seq_len] \n","      sequences.append(\" \".join(seq))\n","\n","    else:\n","      seq = line.split()\n","      for i in range(seq_len - n_token):\n","          seq.append('PAD')\n","      sequences.append(\" \".join(seq))\n","  return sequences\n","\n","X_train_pad = padding(X_train_tweet, 20)\n","X_test_pad = padding(X_test_tweet, 20)"],"metadata":{"id":"QbqatJDhN9hj"},"id":"QbqatJDhN9hj","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# replace the words that only appear once with UNKNOWN\n","def generate_sentence(data):\n","  sequences = []\n","  for line in data:\n","    temp = []\n","    words = line.split()\n","    for word in words:\n","      if word in sorted_words:\n","        temp.append(word)\n","      else:\n","        temp.append('UNK')\n","    sequences.append(\" \".join(temp))\n","  return sequences\n","\n","X_train_final = generate_sentence(X_train_pad)\n","X_test_final = generate_sentence(X_test_pad)"],"metadata":{"id":"8P30CPRaOfyW"},"id":"8P30CPRaOfyW","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"o54nmNt2w4sd","metadata":{"id":"o54nmNt2w4sd"},"outputs":[],"source":["# Using tweets training data vocabulary\n","\n","# Dictionaries to store the word to index mappings and vice versa\n","word2idx = {o:i for i,o in enumerate(sorted_words)}\n","idx2word = {i:o for i,o in enumerate(sorted_words)}\n","\n","\n","# convert text sequences to integer sequences\n","X_train_int = np.zeros((len(X_train_final), 20), dtype = int)\n","for i, data in enumerate(X_train_final):\n","  X_train_int[i] = [word2idx[w] for w in data.split()]\n","\n","X_test_int = np.zeros((len(X_test_final), 20), dtype = int)\n","for i, data in enumerate(X_test_final):\n","  X_test_int[i] = [word2idx[w] for w in data.split()]\n","\n"]},{"cell_type":"code","source":["# convert lists to numpy arrays\n","X_train_int = np.array(X_train_int)\n","y_train_int = np.array(y_train)\n","\n","X_test_int = np.array(X_test_int)\n","y_test_int = np.array(y_test)"],"metadata":{"id":"naTOqvd7Vg6m"},"id":"naTOqvd7Vg6m","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, TensorDataset\n","\n","# create Tensor datasets\n","train_data = TensorDataset(torch.from_numpy(X_train_int), torch.from_numpy(X_train_meta.to_numpy()), torch.from_numpy(y_train_int))\n","test_data = TensorDataset(torch.from_numpy(X_test_int),torch.from_numpy(X_test_meta.to_numpy()), torch.from_numpy(y_test_int))\n","\n","# dataloaders\n","batch_size = 256\n","\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"],"metadata":{"id":"V526jI1Glo7o"},"id":"V526jI1Glo7o","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"7a3ac567","metadata":{"id":"7a3ac567"},"source":["# Glove Embeddings"]},{"cell_type":"code","source":["vectors = bcolz.open(f'{glove_path}/6B.100.dat')[:]\n","words = pickle.load(open(f'{glove_path}/6B.100_words.pkl', 'rb'))\n","words += ['<UNK>', '<s>', '</s>', 'PAD']\n","vocab_list_glove = set(words)\n","new_vecs = np.random.normal(loc=0.0, scale=.6, size=(4,100) )\n","vectors = np.vstack((vectors, new_vecs))\n","word2idx = pickle.load(open(f'{glove_path}/6B.100_idx.pkl', 'rb'))\n","word2idx['<UNK>'] = 400000\n","word2idx['<s>'] = 400001\n","word2idx['</s>'] = 400002\n","word2idx['PAD'] = 400003"],"metadata":{"id":"ZH76mVJhmzE5"},"id":"ZH76mVJhmzE5","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"6ii7TYo3rL1-","metadata":{"id":"6ii7TYo3rL1-"},"outputs":[],"source":["# Using glove weights\n","glove = {w: vectors[word2idx[w]] for w in words}\n","matrix_len = len(sorted_words)\n","weights_matrix = np.zeros((matrix_len, 100))\n","words_found = 0\n","\n","for i, word in enumerate(sorted_words):\n","  try: \n","    weights_matrix[i] = glove[word] # if alr in the vocab, load its pre-trained word vector.\n","    words_found += 1\n","  except KeyError:\n","    weights_matrix[i] = np.random.normal(scale=0.6, size=(100, ))"]},{"cell_type":"markdown","id":"5e5b8d40","metadata":{"id":"5e5b8d40"},"source":["# Neural Net\n","\n","### Retweet Network: Takes in a tweet as input, can use embedded version, and can any combination of bidirectional, LSTM, GRU, concatenates it with metadata vector, and uses a feedforward neural net with 1 hidden layer to perform a regression prediction on the retweet count. "]},{"cell_type":"markdown","id":"96c224d1","metadata":{"id":"96c224d1"},"source":["#### Parameter custom_embeddings is either a tuple: (weight_matrix , none_trainable), or None.\n","#### none_trainable is either True or False or Nothing"]},{"cell_type":"code","source":["def create_emb_layer(weights_matrix, non_trainable=False):\n","  num_embeddings, embedding_dim = weights_matrix.shape\n","  emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n","  emb_layer.load_state_dict({'weight': torch.from_numpy(weights_matrix)})\n","  if non_trainable:\n","      emb_layer.weight.requires_grad = False\n","  return emb_layer, num_embeddings, embedding_dim\n","\n","class RetweetNet(nn.Module):\n","  def __init__(self, vocab_size, hidden_state_sizes, meta_data_len, output_size, embedding_dim, hidden_dim, \n","                 n_layers, drop_prob=0.5, custom_embeddings = None, bidirectional = False, GRU = False):\n","    super().__init__()\n","    self.GRU_val = GRU\n","    self.bidirectional = bidirectional\n","    self.output_size = output_size\n","    self.n_layers = n_layers\n","    self.hidden_dim = hidden_dim\n","        \n","    if custom_embeddings is None: \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    else: \n","        assert len(custom_embeddings) == 2 and isinstance(custom_embeddings, tuple), \"custom embeddings must be of form: (weight_matrix, non_trainable)\"\n","        weights_matrix, non_trainable = custom_embeddings\n","        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, non_trainable)\n","        \n","    if GRU == False: \n","        self.Gate = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True, bidirectional = bidirectional)\n","    else: \n","        self.Gate = nn.GRU(embedding_dim, hidden_dim, n_layers, \n","                              dropout=drop_prob, batch_first=True, bidirectional = bidirectional)\n","    self.dropout = nn.Dropout(0.2)\n","    self.fc1 = nn.Linear(hidden_dim, hidden_state_sizes[0])\n","    self.relu = nn.ReLU()\n","        \n","    #hidden_state_sizes[0] is the size of the output of lstm \n","    self.fc2 = nn.Linear(hidden_state_sizes[0] + meta_data_len, hidden_state_sizes[1])\n","        \n","    #hidden_state_sizes[1] is the size of the first and only hidden layer\n","    self.fc3 = nn.Linear(hidden_state_sizes[1], 1)\n","\n","        \n","  def forward(self, x, meta_data, hidden):\n","    batch_size = x.size(0)\n","    x = x.long()\n","    embeds = self.embedding(x)\n","    gru_out, hidden = self.Gate(embeds, hidden)\n","    gru_out = gru_out.contiguous().view(-1, self.hidden_dim)\n","    \n","    out = self.dropout(gru_out)\n","    out = self.fc1(out)\n","\n","    out = out.view(batch_size, -1, self.hidden_dim)\n","    out = out[:,-1, :] \n","\n","    # combine hidden state and meta_data\n","    ################# ################# #################\n","    #out = torch.cat((out, meta_data), dim = 1) #meta_data is of shape (batch_size, -1)\n","        \n","    out = self.fc2(out)\n","        \n","    # applying dropout before relu since relu already sets some neurons to 0\n","    out = self.dropout(out)\n","    out = self.relu(out)\n","    out = self.fc3(out)\n","        \n","    return out, hidden\n","    \n","  def init_hidden(self, batch_size):\n","    weight = next(self.parameters()).data\n","    n = 1\n","    if self.bidirectional == True: \n","      n = 2\n","    if self.GRU_val == False:\n","      return (weight.new(self.n_layers * n, batch_size, self.hidden_dim).zero_().to('cuda'),\n","              weight.new(self.n_layers * n, batch_size, self.hidden_dim).zero_().to('cuda'))\n","    else:\n","      return  weight.new(self.n_layers * n, batch_size, self.hidden_dim).zero_().to('cuda')\n","\n","\n","def train_retweet_predictor(model, epochs = 100, print_every = 1000, clip = 5, valid_loss_min = np.Inf, lr=0.005, batch_size = 400, device = 'cuda', GRU = False, weight_decay = 1e-5): \n","  counter = 0\n","  print_every = 200\n","  model.train()\n","    \n","  criterion = nn.MSELoss()\n","    \n","  # weight decay is the l2 regularization penalty \n","  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","\n","  training_stats = []\n","  for i in range(epochs):\n","    total_train_loss = 0\n","\n","    h = model.init_hidden(batch_size)\n","    for tweets, meta_data, labels in train_loader:\n","      counter += 1\n","      if GRU == False: \n","        h = tuple([each.data for each in h])\n","      else:\n","        h = h.data\n","      tweets, meta_data, labels = tweets.to(device), meta_data.to(device), labels.to(device)\n","      model.zero_grad()\n","      output, h = model(tweets, meta_data, h)\n","      loss = criterion(output.squeeze(), labels.float())\n","      loss.backward()\n","      total_train_loss += loss.item()\n","      nn.utils.clip_grad_norm_(model.parameters(), clip)\n","      optimizer.step()\n","\n","\n","      if counter % print_every == 0:\n","\n","        print(\"Epoch: {}/{}...\".format(i+1, epochs),\n","            \"Step: {}...\".format(counter),\n","            \"Loss: {:.6f}...\".format(loss.item()))\n","      \n","\n","    #avg_train_loss = total_train_loss / len(train_loader)  \n","    #training_stats.append({'epoch': i + 1, 'Training Loss': avg_train_loss})\n","  \n","  #return training_stats\n","      \n","\n"],"metadata":{"id":"xGLQtrqBeoOr"},"id":"xGLQtrqBeoOr","execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size = len(sorted_words)\n","output_size = len(X_train_int)\n","embedding_dim = 100\n","hidden_dim = 256\n","n_layers = 2\n","\n","net = RetweetNet(vocab_size = vocab_size, hidden_state_sizes = [256,128], meta_data_len = 0, output_size = output_size, embedding_dim = embedding_dim, hidden_dim  = hidden_dim, \n","                 n_layers =n_layers, GRU = True, bidirectional = True)\n","net.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DqetYzck9STm","executionInfo":{"status":"ok","timestamp":1651433601719,"user_tz":240,"elapsed":148,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"781082ba-402b-4574-ed61-45c4e3f766de"},"id":"DqetYzck9STm","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RetweetNet(\n","  (embedding): Embedding(10429, 100)\n","  (Gate): GRU(100, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (fc1): Linear(in_features=256, out_features=256, bias=True)\n","  (relu): ReLU()\n","  (fc2): Linear(in_features=256, out_features=128, bias=True)\n","  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":126}]},{"cell_type":"code","source":["train_retweet_predictor(net, epochs = 10, batch_size = 256, device = 'cuda', lr = 1e-06,GRU = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xpeOpcKL-I9n","executionInfo":{"status":"ok","timestamp":1651433670223,"user_tz":240,"elapsed":67673,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"26e02a94-a4cb-47c7-8914-031db6e6bcf9"},"id":"xpeOpcKL-I9n","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 2/10... Step: 200... Loss: 165.845245...\n","Epoch: 4/10... Step: 400... Loss: 2252.553223...\n","Epoch: 6/10... Step: 600... Loss: 745.528320...\n","Epoch: 8/10... Step: 800... Loss: 664.221497...\n","Epoch: 10/10... Step: 1000... Loss: 92333.000000...\n"]}]},{"cell_type":"code","source":["def error_retweet_predictor(model, batch_size = 359, device = 'cuda', GRU = False): \n","  test_losses = []\n","  num_correct = 0\n","  model.cuda()\n","\n","  h = model.init_hidden(batch_size)\n","  criterion = nn.MSELoss()\n","  \n","\n","  model.eval()\n","  for tweets, meta_data, labels in test_loader:\n","    if GRU == True: \n","      h = h.data\n","    else: \n","      h = tuple([each.data for each in h])\n","    tweets, meta_data, labels = tweets.to(device), meta_data.to(device), labels.to(device)\n","    output, h = model(tweets, meta_data, h)\n","    test_loss = criterion(output.squeeze(), labels.float())\n","    test_losses.append(test_loss.item())\n","    pred = torch.round(output.squeeze())\n","    \n","    correct_tensor = pred.eq(labels.float().view_as(pred))\n","\n","    correct = np.squeeze(correct_tensor.cpu().numpy())\n","\n","    num_correct += np.sum(correct)   \n","   \n","  test_acc = num_correct/len(test_loader.dataset)\n","  print(num_correct, len(test_loader.dataset))\n","  print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n","  print(\"Test accuracy: {:.3f}\".format(test_acc))"],"metadata":{"id":"jy-20t06tV6m"},"id":"jy-20t06tV6m","execution_count":null,"outputs":[]},{"cell_type":"code","source":["error_retweet_predictor(net, batch_size = 256, device = 'cuda', GRU = True) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_QOdfST0z07","executionInfo":{"status":"ok","timestamp":1651433670812,"user_tz":240,"elapsed":606,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"78857bb4-143f-425c-c552-c5033cc433d1"},"id":"r_QOdfST0z07","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1619 6400\n","Test loss: 1469.236\n","Test accuracy: 0.253\n"]}]},{"cell_type":"markdown","source":["### Visualize RetweetNet"],"metadata":{"id":"8Msdu-MQtJMM"},"id":"8Msdu-MQtJMM"},{"cell_type":"code","source":["!pip install torchviz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WUzS4L7qOODm","executionInfo":{"status":"ok","timestamp":1651376775732,"user_tz":240,"elapsed":4599,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"dae79615-8ce4-4d9e-f1a1-633836bb6405"},"id":"WUzS4L7qOODm","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchviz\n","  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.11.0+cu113)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (4.2.0)\n","Building wheels for collected packages: torchviz\n","  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4150 sha256=0108fda8d4a39f8e36420853eb1fcd356cf1ac971fcd7e5b8c065ef75d9066f5\n","  Stored in directory: /root/.cache/pip/wheels/04/38/f5/dc4f85c3909051823df49901e72015d2d750bd26b086480ec2\n","Successfully built torchviz\n","Installing collected packages: torchviz\n","Successfully installed torchviz-0.0.2\n"]}]},{"cell_type":"code","source":["dummy_x = torch.from_numpy(np.zeros((256,20)).astype(np.int64)).to('cuda')\n","dummy_meta = torch.from_numpy(np.zeros((256,8)).astype(np.int64)).to('cuda')\n","dummy_hidden = torch.from_numpy(np.zeros((2, 256, 256)).astype(np.float32)).to('cuda')"],"metadata":{"id":"kfL246JWRrHC"},"id":"kfL246JWRrHC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchviz import make_dot\n","\n","yhat = net(dummy_x, dummy_meta, dummy_hidden)\n","make_dot(yhat, params = dict(list(net.named_parameters()) ), show_attrs=True,show_saved=True).render('something', format = 'png')"],"metadata":{"id":"NxSXNqWTu7X1"},"id":"NxSXNqWTu7X1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install hiddenlayer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qikHNSjqWemD","executionInfo":{"status":"ok","timestamp":1651376799370,"user_tz":240,"elapsed":4172,"user":{"displayName":"Nan Zhou","userId":"06252841090165992312"}},"outputId":"379baf40-3cfe-4b43-dd0d-e90ae7dfd63a"},"id":"qikHNSjqWemD","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting hiddenlayer\n","  Downloading hiddenlayer-0.3-py3-none-any.whl (19 kB)\n","Installing collected packages: hiddenlayer\n","Successfully installed hiddenlayer-0.3\n"]}]},{"cell_type":"code","source":["import hiddenlayer as hl\n","\n","transforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n","\n","graph = hl.build_graph(net, (dummy_x, dummy_meta, dummy_hidden), transforms=transforms)\n","graph.theme = hl.graph.THEMES['blue'].copy()\n","graph.save('rnn_hiddenlayer', format='png')"],"metadata":{"id":"7daHxCEPu-vS"},"id":"7daHxCEPu-vS","execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"buCLM2hT047v"},"id":"buCLM2hT047v","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"0.253Retweet Model clean.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}